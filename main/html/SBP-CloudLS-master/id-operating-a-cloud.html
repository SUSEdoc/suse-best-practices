<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Operating a Cloud</title><meta name="generator" content="DocBook XSL Stylesheets V1.79.2" /><style type="text/css">
body { background-image: url('static/images/draft.png');
       background-repeat: no-repeat;
       background-position: top left;
       /* The following properties make the watermark "fixed" on the page. */
       /* I think that's just a bit too distracting for the reader... */
       /* background-attachment: fixed; */
       /* background-position: center center; */
     }</style><link rel="home" href="index.html" title="Large Scale SUSE OpenStack Clouds - An Architecture Guide" /><link rel="up" href="index.html" title="Large Scale SUSE OpenStack Clouds - An Architecture Guide" /><link rel="prev" href="id-storage.html" title="Storage" /><link rel="next" href="Implementation-Phases.html" title="Implementation Phases" /></head><body onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Operating a Cloud</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="id-storage.html">Prev</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="Implementation-Phases.html">Next</a></td></tr></table><hr /></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="id-operating-a-cloud"></a>Operating a Cloud</h2></div></div></div><p>Setting up a highly scalable cloud environment is a demanding task. But
it is equally important to run it effectively and to maintain it in a way
that allows the provider to benefit from the economy of scale.
<span class="emphasis"><em>Economy of scale</em></span> is a term often used to describe a major benefit
that results from running a cloud. If all processes are standardized and
automated properly, adding more nodes to the installation is easy and
can be done without a lot of effort. The goal is to get all required
functionality in place right from the start and then profit from it
whilst the cloud can be scaled.</p><p>This chapter focuses on the most important aspects of running and
maintaining a large scale cloud environment. It covers the major tasks
of the operational everyday’s business: system maintenance, monitoring,
and log files.</p><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-maintaining-hundreds-of-hosts"></a>Maintaining Hundreds of Hosts</h3></div></div></div><p>Automation is no new trend in IT. Until 10 years ago, many companies
ignored the need for automation because they had simply not been used
to the concept. But solutions such as Puppet, Salt, and Ansible have made
clear that automation is the key to maintaining the own infrastructure
more effectively and cheaper. It is no longer recommended to pay for highly
skilled engineers and architects to perform tasks that can be
automated. Automation frees up skilled personnel to focus on developing
new product features and technologies.</p><p>Automation is essential for a successful cloud implementation. In this case,
what is true for small and conventional setups is even more true for a typical
cloud environment that consists of dozens, hundreds or thousands of nodes.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-automation-is-key"></a>Automation Is Key</h4></div></div></div><p>One of the central design targets of clouds is the ability to scale out.
This is from particular importance for public cloud environments.
At any point in time, a new customer can show up and request to get a
higher amount of resources. Even if the cloud provider manages to
provide resources to a customer because of the resource buffer they had
planned for the platform (usually 25-30% of the total
resources available), they still need to scale out quickly to re-create new
buffer and to allow for further growth.</p><p>If performed manually, adding dozens or hundreds of nodes in parallel to a
setup can be a tedious task. However, it can also be a quite convenient
task that does not involve a lot of human intervention.</p><p>In cloud environments, the entire lifecycle of physical machines must
be automated as much as possible. This means that automation technologies
must be in place long before the Linux operating system is installed on
the target system. The only manual part in the process of adding new nodes
should be the physical installation of a machine in the rack. All the other
tasks should be included in an automated process.</p><p>First, the machine boots into a network-based tool to inventory and
prepare the system. Then, an automated installation of the operating
system is performed. Finally, required software along with the necessary
configuration is installed on the machine via automation tools such as Salt
or Ansible.</p><p>SUSE OpenStack Cloud comes with tools that allow administrators to capitalize
on an automated work stream, supporting features such as the automation of the
following:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Discovery of (new) hardware</p></li><li class="listitem"><p>Installation of an operating system</p></li><li class="listitem"><p>Management of system and application configuration</p></li><li class="listitem"><p>Maintenance of installed software (Updates / Upgrades)</p></li></ul></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-a-working-maintenance-concept"></a>A Working Maintenance Concept</h4></div></div></div><p>Getting systems up is not the only relevant task. Having a complete
and well-designed maintenance scheme in place is just as important. One
big challenge are security updates. Many security updates require the
installation of new packages on the affected systems. Some updates
require a new version of the Linux kernel which results in the affected servers
to be rebooted. Rebooting hundreds or thousands of servers in a coordinated
and controlled manner is a complex task. For this purpose, SUSE OpenStack
Cloud offers tools that not only support the installation of updates in a
centralized way but also perform complete reboots of the environment.</p><p>In a working maintenance concept, the central system management service takes
on the key role. It ensures a stable and controlled software distribution,
the staging of updates, and the automatic roll-out of patches and configurations.
SUSE Manager offers all these functionalities and helps with compliance
features like the <span class="emphasis"><em>CVE search</em></span> to handle a large number of Linux nodes.</p><p>A working maintenance concept for clouds also needs to define several
processes specific to the setup in question. Processes are usually highly
adapted to the environment where they are used, including factors such
as the company running the setup.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-some-approaches-will-fail"></a>Some Approaches Will Fail</h4></div></div></div><p>Because of the specific functionalities shipped with SUSE OpenStack Cloud
and SUSE Enterprise Storage, most work related to installing and maintaining
the platform is done in an automated manner. Administrators need to make
sure though that they do not make void some of these functionalities by
design decisions related to their scale-out cloud projects.</p><p><a id="Ephemeral-Issues"></a>One regular issue, for example, is local storage in virtual machines
inside the cloud. As explained in the storage chapter, the local
storage of virtual machines in clouds is called <span class="emphasis"><em>ephemeral</em></span>
storage. On the systems, the <span class="emphasis"><em>temporary</em></span> local storage devices of VMs
are usually local images residing on a storage device inside the host
where the VM is running. This is often a fast Solid State Drive (SSD).
That is why, from the user perspective, running production workload based
on ephemeral storage is tempting. It features much higher IOPS values and
notably less latency than network-connected storage such as Ceph volumes.
The issue with local storage in individual nodes of the setup
is that they are not redundant and not replicated somewhere. Cloud
providers cannot make guarantees on the availability of the ephemeral disks
of individual VMs.</p><p>A conclusive example for why using local, ephemeral storage in VMs is not
an option is a cloud-wide reboot of all servers because of necessary
security updates. The large cloud providers can reboot their
machines and assume that applications deployed on top of the cloud are
designed in a redundant way. Companies serving customers with less modern
applications might choose a compromise and migrate the individual VMs away
from physical servers that are about to be rebooted. But this live migration
can only be done successfully if the VM’s data reside on volumes that can
easily be detached from one host and attached to another. VMs using ephemeral
storage only cannot be migrated. At worst, they make it even impossible to
reboot individual physical servers. This heavily violates the principle of
the economy of scale.</p><p>It is important to ensure that ephemeral storage is not abused by users for
purposes it does not fit for, and to ensure that useful alternatives such
as highly-performing Ceph storage are available.</p><p>Companies planning to set up a cloud need to determine their target
architecture carefully, including their requirements for storage.
Implementations with mixtures of local and shared ephemeral storage are,
while technically possible, a complex matter and need thorough consideration.
Getting support from knowledgeable experts on the matter is recommended.</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-monitoring-openstack-environments"></a>Monitoring OpenStack Environments</h3></div></div></div><p>When SUSE OpenStack Cloud and SUSE Enterprise Storage are up and running,
it is important to monitor both solutions properly. Efficient monitoring
is the only way to ensure that faults and issues are detected immediately
and can be handled appropriate.</p><p>When talking about <span class="emphasis"><em>monitoring</em></span>, administrators used to conventional setups
will think of well-known and conventional monitoring tools such as Nagios
or Zabbix. These tools are excellent choices for event-based monitoring in
conventional setups, as they reliably identify failure events and trigger
alarms.</p><p>Most of these tools, however, are not state-of-the-art anymore. In addition,
event-based monitoring is not the only kind of surveillance required in
a cloud. Another very important requirement in clouds is the ability to have
an overview of the current load, the historical load and the likely
development of load in the nearer future. This functionality is called
<span class="emphasis"><em>trending</em></span> and requires the collection of respective metric values from all
nodes in the cloud.</p><p>Solutions suitable for monitoring cloud environments and recording the
metric values required for trending are referred to as <span class="emphasis"><em>Monitoring, Alerting,
Trending</em></span> (MAT).</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-vms-and-the-platform-itself"></a>VMs and the Platform Itself</h4></div></div></div><p>When the subject is <span class="emphasis"><em>Monitoring the cloud</em></span>, a clear distinction must be
made between monitoring individual VMs in the cloud and monitoring the
underlying infrastructure of the cloud. Many public cloud providers do
not care about the status of their customers' VMs. But they offer
a software service which their cloud customers can configure to monitor
their VMs and other services. This additional service is called
<span class="emphasis"><em>Monitoring as a Service</em></span>. OpenStack offers a solution for it, which
is discussed further down in this chapter.</p><p>In contrast to monitoring the VMs stands the necessity to monitor all
components that form the physical and the logical infrastructure of the
cloud. Besides OpenStack and Ceph, all accompanying services such as
RabbitMQ, MariaDB, and all devices for network infrastructure and for
power supply must be monitored.</p><p>The following paragraphs describe solutions for both the monitoring of
VMs in the cloud and the monitoring of the cloud itself.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-disadvantages-of-conventional-tools-in-cloud-environments"></a>Disadvantages of Conventional Tools in Cloud Environments</h4></div></div></div><p>Prior to this, however, it is necessary to explain the differences between
cloud monitoring tools and conventional solutions such as Nagios or Zabbix.
As mentioned before, trending is an important aspect of keeping control of
the platform. Conventional solutions often provide features for trending.
Nagios for example offers PNP4Nagios, Zabbix also comes with built-in
trending capabilities. Most of these solutions suffer from an inherent
design flaw; they store trending data in relational databases
such as MariaDB or PostgreSQL. However, this represents a serious
performance bottleneck. The data model of said databases does not match
the format of metric data required for cloud trending.</p><p>The example below explains what this means in detail.</p><p>An administrator wants to know how the usage of virtual CPUs has developed in
a specific platform during the last year. The monitoring solution
has recorded the required data and stored all values in MariaDB. But to
generate a concise and understandable outcome in the form of a graphic, the
monitoring software needs to run an utterly large MariaDB query that reads
individual lines from those tables in MariaDB that hold the data. All collected
data is then drawn into a graphic and displayed to the user.</p><p>The database query is very resource-intensive, and the example above covers
only the <span class="emphasis"><em>read</em></span> aspect of trending. The <span class="emphasis"><em>write</em></span> aspect is even worse. If every
system has 200 metric values that the administrator wants to fetch every 15
seconds, they can end up with hundreds of thousands of SQL queries per minute,
depending on the overall amount of nodes in the setup. Such a load
quickly brings every MariaDB instance to its limits. Even if the MariaDB
instance survives the load, the generation of the graphic and trending in
general are slow and tedious.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-an-introduction-to-monitoring-alerting-and-trending"></a>An Introduction to Monitoring, Alerting and Trending</h4></div></div></div><p>Modern solutions for Monitoring, Alerting and Trending (MAT) also use
databases to store data, but in contrast to conventional solutions they do
not use relational databases such as MariaDB. Instead, they use Time Series
Databases (TSDB), which operate completely different. TSDBs are not based
upon tables and rows but align all data on a single root element which is
the timeline itself. Queries like the one mentioned previously are very easy
to serve that way. Because data is stored in the database in the same format
that it is supposed to be displayed in, gathering metric data on a certain
time period from TSDBs is easy and convenient from both the
administrator’s and database’s point of view.</p><p>One advantage of this kind of trending is that also basic monitoring can
be done using the same technology. Metrics can almost arbitrarily
be defined in modern TSDB implementations as long as they can be expressed
in a numeric value. For example, one metric could be "number of Apache
Web server processes in operation on a host". If said number falls
below the desired value, the TSDB triggers an alarm. It is important to
understand that, while metric-based monitoring can by done by all TSDB
implementations, event-based alerting is not available in every TSDB
implementation. Further down in this chapter it is explained why
that is not necessarily a disadvantage in massive scale-out setups.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-variant-1-monasca"></a>Variant 1: Monasca</h4></div></div></div><p>Monasca is OpenStack’s solution for both <span class="emphasis"><em>Monitoring as a Service</em></span> and the
monitoring of the OpenStack platform itself. Monasca is an official
OpenStack service and supported by SUSE OpenStack Cloud. Monasca consists of
many components that work hand in hand to ensure an efficient and
smooth-running monitoring solution.</p><p>Several components such as the <span class="emphasis"><em>Kafka</em></span> stream processing engine play a role
in the Monasca monitoring environment. The persistent storage of data for
long-term trending is done using a TSDB and follows modern standards. The
<span class="emphasis"><em>monasca-agent</em></span> component collects every metric available on the target
systems (physical machines or VMs) and transports it back to the central
Monasca engine.</p><p>As an OpenStack service, Monasca is deeply integrated with all other OpenStack
services. It uses Keystone for authentication and works well with the other
OpenStack components. Monasca can also be accessed using Grafana, the leading
open source solution for visualizing trending data.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-variant-2-prometheus-and-its-components"></a>Variant 2: Prometheus and Its Components</h4></div></div></div><p>If Monascana is not the ideal solution for a particular setup, a good
alternative is Prometheus. It features a TSDB that comes
with several additional components to allow for a smooth monitoring
experience. Prometheus itself is the core of the environment and takes
care of storing collected metrics from the individual physical hosts in
the cloud.</p><p>Prometheus comes with a separate program to collect metric data on the
target systems, the so called Prometheus <span class="emphasis"><em>Node Exporter</em></span>. <span class="emphasis"><em>Exporter</em></span> is
a synonym for <span class="emphasis"><em>agent</em></span> in the Prometheus universe because the exporters
act like agents. They communicate with Prometheus via a standardized API.
Because Prometheus is, like Monasca, open source software, that API is
openly checkable and fully documented. Consequently, a lot of open source
projects are defining interfaces for metric data aggregation in their
applications or provide separate exporters for their programs that can be
combined with Prometheus. In this regard, Prometheus can be considered more
versatile than Monasca, which is very much OpenStack-specific.</p><p>Prometheus also comes with an AlertManager that generates alerts based on
pre-defined rules. For these rules, Prometheus developers have invented
a new query language that is similar to but not identical with SQL.</p><p>The previously mentioned Grafana visualization solution for metric data has
a back-end driver for Prometheus and can connect to it natively. The same
holds for Ceph, which offers a Prometheus-compatible interface that the
solution can read Ceph metric data from without using any additional exporter,
because Ceph has a Prometheus metric data exporter built-in.</p><p>Lastly, Prometheus can easily be combined with all the tools
in the <span class="emphasis"><em>TICK</em></span> stack created by InfluxDB. This is especially helpful for
the storage of trending-data on a long-term base (this means several years of
all kinds of historical metric data). InfluxDB is better suited
for this task than Prometheus. Combining both solutions allow
administrators to get the best from both worlds.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-monasca-or-prometheus-there-is-choice"></a>Monasca or Prometheus: There Is Choice</h4></div></div></div><p>Monasca and Prometheus are only two examples for the many options
to properly monitor an OpenStack installation. If you have a time
series-based monitoring solution in place, it is possible to extend
the solution to support OpenStack. An important question is whether you
want to monitor the OpenStack setup only or also VMs running on it. If you
want to monitor both, Monasca is likely the best choice. If flexibility, in
respect of the collection of metrics is relevant, Prometheus offers more
options than Monasca, which is precisely tailored to the OpenStack use case.</p><p>Whatever solution you choose, it is important to understand that large scale
environments need monitoring, alerting and trending. Solutions that
administrators are used to for historical reasons might not be suitable for
this purpose.</p></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-knowing-what-is-going-on-logging"></a>Knowing What Is Going On: Logging</h3></div></div></div><p>Many MAT solutions are good for trending-based metric types but not for
event-based alerting. That is because a scale-out environment can produce
a much higher number of alerts a conventional monitoring solution can handle.</p><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-the-need-for-centralized-logging"></a>The Need for Centralized Logging</h4></div></div></div><p>Large environments must have a central solution for logging in place.
When debugging an issue under stress, an administrator
cannot login to dozens or hundreds of servers and search the local logs on
these machines for certain indicators. Instead, administrators need a
solution that aggregates relevant logs from all machines and makes them
available through an indexed, searchable database.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-how-monitoring-logging-go-hand-in-hand"></a>How Monitoring &amp; Logging Go Hand in Hand</h4></div></div></div><p>Having a solution for centralized logging in place makes monitoring events
by means of a TSDB easier. When a valid metric is defined for a certain event,
and when that event triggers an alert in the monitoring system, the
administrator can log in to the centralized log aggregation system and
examine the logs of the affected system. Tedious SSH jumping is not necessary
anymore.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-variant-1-elk"></a>Variant 1: ELK</h4></div></div></div><p>A variant to create centralized logging based on open source
software is the <span class="emphasis"><em>ELK</em></span> stack. ELK is an acronym for <span class="emphasis"><em>ElasticSearch</em></span>,
<span class="emphasis"><em>Logstash</em></span> and <span class="emphasis"><em>Kibana</em></span> and refers to three components that are deployed
together. ElasticSearch is the indexing and search engine that received log
entries from systems. Logstash collects the log files from the target systems
and sends them to ElasticSearch. Kibana is a concise and easy-to-use interface
to Logstash and ElasticSearch and allows for web-based access.</p><p>Although these three components are not always combined, the acronym <span class="emphasis"><em>ELK</em></span>
has become an established term for this solution. Sometimes, for example the
Logstash component is replaced by <span class="emphasis"><em>Fluentd</em></span> or other tools for log aggregation.
The excellent versatility of this solution is one of its biggest advantages.</p><p>When using Monasca for MAT, ELK is recommended for logging. Monasca integrates
well with ELK and you can combine these two tools to get an efficient solution.</p></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-variant-2-splunk"></a>Variant 2: Splunk</h4></div></div></div><p>A commercial alternative to the ELK stack is <span class="emphasis"><em>Splunk</em></span>. It
is recognized by system administrators for its simple setup and usability.
It can easily be extended with new features, and there is an entire ecosystem
for the solution, boosted by the company behind Splunk.</p><p>The disadvantage is that Splunk has a charging model based on the amount of
transferred log files. As OpenStack tends to generate a lot of logs,
in large scale environments, the amount of logs in these setups is very high.
Splunk licenses become a relevant cost factor in budget plannings.
A huge advantage however is that administrators get a well-working solution
for large scale environments.</p></div></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="id-storage.html">Prev</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="Implementation-Phases.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Storage </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> Implementation Phases</td></tr></table></div></body></html>
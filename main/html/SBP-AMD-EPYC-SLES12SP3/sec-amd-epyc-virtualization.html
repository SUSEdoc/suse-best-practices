<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Using AMD EPYC for Virtualization</title><meta name="generator" content="DocBook XSL Stylesheets V1.79.2" /><style type="text/css">
body { background-image: url('static/images/draft.png');
       background-repeat: no-repeat;
       background-position: top left;
       /* The following properties make the watermark "fixed" on the page. */
       /* I think that's just a bit too distracting for the reader... */
       /* background-attachment: fixed; */
       /* background-position: center center; */
     }</style><link rel="home" href="index.html" title="Optimizing Linux for AMD EPYC with SUSE Linux Enterprise 12 SP3" /><link rel="up" href="index.html" title="Optimizing Linux for AMD EPYC with SUSE Linux Enterprise 12 SP3" /><link rel="prev" href="sec-candidate-workloads.html" title="Candidate Workloads" /><link rel="next" href="sec-conclusion.html" title="Conclusion" /></head><body onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Using AMD EPYC for Virtualization</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="sec-candidate-workloads.html">Prev</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="sec-conclusion.html">Next</a></td></tr></table><hr /></div><div class="sect1"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="sec-amd-epyc-virtualization"></a>Using AMD EPYC for Virtualization</h2></div></div></div><p>On first approximation, Virtual Machines (VMs) can be considered
      as large (in terms of memory footprint) and long running
      applications. Thus the tuning described so far in the paper can be
      applied.</p><p>However, when taking into account more specific aspects and
      characteristics of VMs, and making specific considerations about
      virtualization, a better tailored and more effective set of tuning
      advice can be derived. This is especially relevant for NUMA systems,
      such as AMD EPYC:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>VMs are long running activities, and typically use much more
          memory than <span class="quote">“<span class="quote">regular</span>”</span> OS processes.</p></li><li class="listitem"><p>VMs can be configured to be, and act, both like NUMA-aware
          and non NUMA-aware workloads.</p></li></ul></div><p>Calling VMs <span class="quote">“<span class="quote">long running activities</span>”</span> means that
      they often run for hours, days, or even months, without being
      terminated or restarted. Therefore, it is almost never acceptable to
      pay the price of suboptimal resource partitioning and allocation,
      even when there is the expectation that things will be better next
      time. Poor mapping of virtual machine resources (virtual CPUs and
      memory, but also I/O) on the host topology may cause issues to
      everything that runs inside the virtual machine – and potentially
      even to other components of the system – for a long time.</p><p>With reference to NUMA-awareness, a VM is called out to be NUMA
      aware, if a (virtual) NUMA topology is defined and exposed to the VM
      itself, and if the OS that the VM runs (guest OS) is NUMA-aware. On
      the contrary, a VM is called NUMA-unaware, if either no (virtual)
      NUMA topology is exposed, or the guest OS is not NUMA-aware.</p><p>In general, VMs that are large enough (in terms of amount of
      memory and number of virtual CPUs) to span multiple host NUMA nodes,
      benefit from being configured as NUMA-aware VMs. However, even for
      small and NUMA-unaware VMs, intelligent placement of their memory on
      the host nodes, and effective mapping of their virtual CPUs (vCPUs)
      on the host physical CPUs (pCPUs) is key for achieving good and
      consistent performance.</p><p>The following sections of this paper focuses on tuning for CPU
      and memory intensive VMs, and leave IO aside. More specifically, it
      focuses on how to configure and tune one or more VMs, so that CPU and
      memory intensive workloads running inside them can achieve the best
      performance.</p><p>It is highly desirable that vCPUs run close to the memory that
      they are accessing (for example on the same node). For reasonably big
      NUMA-aware VMs that requires properly mapping the virtual NUMA nodes
      of the guest to physical NUMA nodes on the host. For smaller NUMA-
      unaware VMs that means allocating all their memory on the smallest
      possible number of host NUMA nodes (better if just one), and making
      their vCPUs run on the pCPUs of those nodes respectively that
      node.</p><p>Both the Kernel-based Virtual Machine (KVM) and the Xen-Project
      hypervisors, as they are available in SUSE Linux Enterprise Server 12
      SP3, provide (slightly different) mechanisms to enact this kind of
      resource partitioning and allocation.</p><div class="sect2"><div class="titlepage"><div><div><h3 class="title"><a id="sec-preparing-host-virtualization"></a>Preparing the Host for Virtualization</h3></div></div></div><p>Giving details on how to install and configure a system, so
        that it becomes a suitable virtualization host, is outside of the
        scope of this paper. For instructions and details refer to the SUSE
        documentation at <a class="link" href="https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-vt-installation.html" target="_top">https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-vt-installation.html</a>
        .</p><p>The same applies to configuring both the system’s and the VMs’
        networking and storage. For specific details refer to the operating
        system, libvirt or hypervisor documentation and manuals. For
        example, to know how to assign network interfaces (or ports) to one
        or more VMs for improved network performance, refer to the SUSE
        documentation at <a class="link" href="https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-libvirt-config.html#sec-libvirt-config-pci" target="_top">https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-libvirt-config.html#sec-libvirt-config-pci</a>
        .</p></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title"><a id="sec-vm-types"></a>Virtual Machine Types</h3></div></div></div><p>KVM only supports one type of VM – a fully hardware-based
        virtual machine (HVM). Under Xen, VMs can be paravirtualized (PV)
        or hardware virtualized machines (HVM). Xen also supports mixed
        modes. For example, hardware virtualized VMs can use some
        paravirtualized interfaces.</p><p>Xen HVM guests with paravirtualized interfaces enabled (often
        called PVHVM, or for brevity, HVM) are very similar to KVM VMs
        (which also use both hardware virtualization and paravirtualized
        IO, namely virtIO). This paper is always referring to PVHVM VMs
        when talking about VMs running on Xen.</p></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title"><a id="sec-oversubscription-host"></a>Oversubscription of Host Resources</h3></div></div></div><p>Oversubscription happens when the demand for some resource is
        higher than is physically available. In virtualization, this is
        typical for vCPUs, and can also happen for memory. </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Not Covering Oversubscribed Scenarios</h3><p>Given the large number of CPUs that can be available on an
          EPYC system (128 in the example in <a class="xref" href="sec-epyc-topology.html#fig-epyc-topology" title="Figure 1. EPYC Topology">Figure 1, “EPYC Topology”</a>), and the huge amount of memory
          the architecture supports, not covering oversubscribed scenarios
          is not considered a limitation, at least as far as this paper is
          concerned.</p></div><p>In any case, most of the tuning that will be illustrated here
        is valid for oversubscribed systems as well. VM configuration
        advises can easily be adapted to be effective in such a
        scenario.</p><h4><a id="id1846"></a>
        <span class="italic">CPU Oversubscription</span>
      </h4><p>CPU oversubscription is what happens when, on a 128 physical
        CPUs system, the administrator creates, for example, 200 single
        vCPU guests. It is impossible to say whether this configuration is
        good, and should be encouraged, or bad, and should be avoided or
        forbidden, without further knowledge about the actual goals of the
        system itself, and – even more important – about the
        workloads.</p><p>As an example, if the load on each vCPU will always stay below
        50 percent, oversubscribing by a factor of 2 would not only be
        tolerated, but would be advisable to avoid wasting resources. In
        this scenario that means creating 256 single vCPU VMs on the 128
        pCPUs host is a good configuration (this, for simplicity, does not
        take into account the host OS, which will be discussed later). On
        the contrary, if it is known that the load on each vCPU will always
        be 100 percent, creating even 129 single vCPU VMs is already a
        misconfiguration (although it would likely be tolerated and handled
        well).</p><p>After all, hypervisors have schedulers to deal correctly with
        situations when there are more runnable entities (that is, vCPUs)
        than there is capacity to actually execute them at the same time
        (that is, pCPUs). The benefit of running more workloads (that is,
        VMs) than the hardware would allow comes at the price of reduced
        throughput and increased latency for the workloads themselves. As
        the focus of this paper is mainly on CPU and memory intensive
        workloads, which fully load the vCPUs on which they run than on IO
        bound ones, CPU oversubscription is out of scope here and only
        briefly mentioned.</p><h4><a id="id1851"></a>
        <span class="italic">Memory Oversubscription</span>
      </h4><p>There are a few ways of achieving memory oversubscription. The
        first, which we can call <span class="quote">“<span class="quote">classical memory
          oversubscription</span>”</span>, is what happens when an administrator
        creates VMs with a total cumulative memory footprint greater than
        the amount of physical RAM on the host. This only works if some of
        such memory is kept outside of the RAM (<span class="italic">swapped out</span>) when the VMs using it are not running
        and put back inside of the RAM (<span class="italic">swapped
          in</span>) when they are. Oversubscribing memory on KVM only
        requires creating VMs whose total amount of memory exceeds the
        host’s RAM. The usual Linux kernel virtual memory management and
        paging mechanisms will be used to handle that. On Xen, this variant
        of memory oversubscription is not possible unless special
        technologies (for example, the <span class="package">xenpaging</span> tool
        and/or transcendent memory) are employed.</p><p>Another way of doing memory oversubscription is page sharing or
        page merging. This is based on the principle that if two (or more)
        VMs happen to use two (or more) pages, the content of which is
        identical, it would be enough to keep one in memory and only refer
        to it from the other places. Similar to overcommitting via paging,
        this is available natively on KVM via a mechanism called <span class="italic">Kernel Samepage Merging (KSM)</span>. On Xen,
        it needs special actions.</p><p>Finally, there is memory ballooning. This concept is based on
        the fact that VMs may not need all the memory they are given by the
        system administrator all the time. This means, although a VM will
        appear to always have all its memory, some of that memory is not
        actually allocated onto the host RAM (ballooned down) until the VM
        actually uses it (ballooning up). This is supported in both Xen and
        KVM.</p><p>Whichever method is used, allowing memory oversubscription has
        both latency and throughput implications. This makes it not ideal for
        the workloads considered in this paper, and it is therefore not
        further explored here.</p><h4><a id="id1862"></a>
        <span class="italic">Oversubscription with a single
          VM</span>
      </h4><p>In the case where only one VM is configured on the host,</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>a single VM should never have more vCPUs than the host has
            pCPUs.</p></li><li class="listitem"><p>a single VM should never have more memory than the host has
            physical RAM.</p></li></ul></div></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title"><a id="sec-resource-allocation-tuning-host"></a>Resource Allocation and Tuning of the Host</h3></div></div></div><p>The main purpose of a system being used as a virtualization
        host is running VMs. To do that effectively, there are activities
        which reside and run on the host Operating System (host OS). These
        processes require some resources and are subject to being tuned. In
        fact, on both Xen and KVM, the host OS is at least responsible for
        helping with the IO performed by the VMs.</p><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-allocating-resources-hostos"></a>Allocating Resources to the Host OS</h4></div></div></div><p>It is generally recognized as a good practise to make sure
          that the host OS has some resources assigned to itself. This may
          mean that some physical CPUs, and some memory, will be
          exclusively granted to the host OS. </p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Host OS on KVM and on Xen</h3><p>While on KVM the host OS is the actual Linux operating
            system that loads the hypervisor kernel modules, on Xen the
            host OS runs inside what is effectively a very special guest
            VM.</p></div><p>It is hard to give general recommendations but a rule of
          thumb (validated by other performance tuning efforts) suggests
          that 5 percent to 10 percent of the physical RAM should be
          assigned to the host OS. Even more, in case the plan is to run
          hundreds of VMs. However, if using Xen, that can be reduced to a
          few gigabytes, even when planning to spawn many VMs. This is
          especially true if disaggregation is used (see <a class="link" href="https://wiki.xenproject.org/wiki/Dom0_Disaggregation" target="_top">https://wiki.xenproject.org/wiki/Dom0_Disaggregation</a>
          ).</p><p>In terms of CPUs, on <span class="quote">“<span class="quote">traditional NUMA systems</span>”</span>,
          where NUMA nodes correspond to sockets, it is usually advised to
          reserve one physical core (which means two logical CPUs,
          considering hyperthreading) per socket for the host OS. This
          translates to one physical core per node on EPYC. Usually it will
          be fine to assign less CPUs than that to the host OS, but it is
          better to always give one core to it, for each node that has IO
          channels attached. Host OS activity is mostly related to
          performing IO, and the kernel threads dedicated to the handling
          of actual devices, which are often bound to the nodes on which
          the devices are attached, are better when given good chances to
          run without much contention. In the example architecture shown in
            <a class="xref" href="sec-epyc-topology.html#fig-epyc-topology" title="Figure 1. EPYC Topology">Figure 1, “EPYC Topology”</a> this would mean reserving
          one physical core for the host OS on nodes 0, 1, 3, 4 and
          5.</p><p>As system administrators need to be able to reach out and
          login to the system, to manage and troubleshoot it, some
          resources should be reserved for management consoles, and the
          chosen hypervisor's toolstack (for example, the <span class="strong"><strong>SSH</strong></span> daemon and the <span class="strong"><strong>libvirt</strong></span> daemon).</p><p>All that has been described so far is greatly workload
          dependent. Since each VM does some IO, the ideal setup would be
          to dedicate one host physical or logical core to doing IO for
          each device used by each VM (or at least for those devices
          important for the specific workload, for example, network IO, for
          VMs doing network intensive activities). But this reduces the
          number of CPUs available for running VMs, which may be a problem.
          Also, considering that this grants sensible performance
          improvements only to IO intensive workloads (which are outside of
          the scope of this paper anyway), it may not be considered
          worthwhile.</p><p>If the overall goal of the system is running one or two big
          VMs, for example on a host like the one in <a class="xref" href="sec-epyc-topology.html#fig-epyc-topology" title="Figure 1. EPYC Topology">Figure 1, “EPYC Topology”</a>, with 128 (logical) CPUs – and
          each VM as 4 IO devices – it is sufficient to reserve</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>4 cores (8 logical CPUs) for the host IO
              controllers,</p></li><li class="listitem"><p>either 4 (for 1 VM) or 8 (for 2 VMs) cores or threads for
              the IO of the VMs,</p></li><li class="listitem"><p>and 1 core for system management</p></li></ul></div><p>That still leaves 128-8-4-2=114 (for 1 VM) or 128-8-8-2=100
          CPUs available. On the other hand, if the goal is to run many
          small VMs, <span class="quote">“<span class="quote">losing</span>”</span>, for example, one CPU per VM
          (plus, again, 8 for IO controllers and 2 for management) means
          not being able to start more than 128-8-2=118/2=59 VMs.</p><p>To summarize, considering the focus of this paper on CPU and
          memory intensive workloads, the recommendation is to exclusively
          assign to the host OS <span class="strong"><strong>one</strong></span>
          physical CPU per NUMA node. Referring to the hardware shown in
            <a class="xref" href="sec-epyc-topology.html#fig-epyc-topology" title="Figure 1. EPYC Topology">Figure 1, “EPYC Topology”</a>, that means 8 physical
          cores (equivalent to 16 logical CPUs) should be assigned.</p><h5><a id="id1902"></a>
          <span class="italic">Allocating Resources to the host OS on
            KVM</span>
        </h5><p>When using KVM, sparing 8 cores and 12 GB of RAM for the host
          OS is done by stopping the creation of VMs when the total number
          of vCPUs for these VMs has reached 120, and when the total
          cumulative amount of allocated RAM has reached 244 GB.</p><p>Following all the advice and recommendations from this paper
          (including the ones given later about VM configuration) will
          automatically make sure that the unused CPUs are available to the
          host OS. There are many other ways to enforce this (for example
          with <span class="package">cgroups</span> and <span class="package">cpusets</span>).
          These methods are not described in this paper.</p><h5><a id="id1908"></a>
          <span class="italic">Allocating Resources to the host OS on
            Xen</span>
        </h5><p>When using Xen, host OS (also called <span class="quote">“<span class="quote">Domain 0</span>”</span>
          or <span class="quote">“<span class="quote">Dom0</span>”</span>) resource allocation needs to be done
          explicitly, at system boot time. Giving 8 physical cores and 12
          GB of RAM to Dom0 is done by specifying the following additional
          parameters on the hypervisor boot command line (for example, by
          properly editing <code class="filename">/etc/defaults/grub</code>, and
          then updating the boot loader):</p><pre class="screen">dom0_mem=12288M,max:12288M dom0_max_vcpus=16</pre><p>The number 16 comes from the reservation of 8 physical cores,
          which, because of hyperthreading, are 16 logical CPUs. 12288
          memory (== 12 GB, in megabytes (MB)) is specified twice to
          prevent Dom0 from using ballooning, which is not recommended (see
            <a class="link" href="https://wiki.xenproject.org/wiki/Tuning_Xen_for_Performance#Memory" target="_top">https://wiki.xenproject.org/wiki/Tuning_Xen_for_Performance#Memory</a>
          ).</p><p>Making sure that Dom0 vCPUs run on specific pCPUs is not
          strictly necessary. It can be enforced, but since Dom0 is a
          (special) VM this is only possible via the Xen scheduler. There
          is no mechanism to communicate this configuration at Xen boot
          time. Consequently it must be done when the system is live, by
          specifying the vCPU affinity of Dom0’s vCPUs. Using the Xen’s
          default <span class="package">xl</span> toolstack, it looks as follows:</p><pre class="screen">
xl vcpu-pin 0 0 0
xl vcpu-pin 0 1 1
xl vcpu-pin 0 2 8
xl vcpu-pin 0 3 9
...
xl vcpu-pin 0 12 48
xl vcpu-pin 0 13 49
xl vcpu-pin 0 14 56
xl vcpu-pin 0 15 57
</pre><p>Or, using libvirt’s <span class="package">virsh</span>, it looks as
          follows:</p><pre class="screen">
virsh vcpupin 0 --vcpu 0 --cpulist 0
virsh vcpupin 0 --vcpu 1 --cpulist 1
virsh vcpu-pin 0 --vcpu 2 --cpulist 8
virsh vcpu-pin 0 --vcpu 3 --cpulist 9
...
virsh vcpupin 0 --vcpu 12 --cpulist 48
virsh vcpupin 0 --vcpu 13 --cpulist 49
virsh vcpupin 0 --vcpu 14 --cpulist 56
virsh vcpupin 0 --vcpu 15 --cpulist 57
</pre><p>As mentioned above, this cannot be done via boot time
          parameters, and must happen after the system is booted. However,
          it can be automated via a custom init script (<span class="command"><strong>virsh
            vcpupin –config …</strong></span> is not effective for Dom0).</p><p>If you want to limit Dom0 to only a specific (set of) NUMA
          node(s), the <span class="command"><strong>dom0_nodes=&lt;nodeid&gt;</strong></span> boot
          command line option can be used. This will affect both memory and
          vCPUs. This means that memory of Dom0 will be allocated on the
          specified node(s), and the vCPUs of Dom0 will be restricted to
          run on those same node(s). It is possible to change on-line on
          what pCPUs you want Dom0’s vCPUs to run (as shown either via
            <span class="command"><strong>xl vcpu-pin</strong></span> or <span class="command"><strong>virsh
            vcpupin</strong></span>), but its memory will always stay where it
          was allocated during boot. On EPYC, at least for the purposes and
          the scope of this paper, this option is not recommended.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-trasparent-huge-pages"></a>(Transparent) Huge Pages</h4></div></div></div><p>For virtualization workloads, rather than using Transparent
          Huge Pages on the host, it is recommended that huge pages (1 GB
          size, if possible) are used for the memory of the VMs. This
          sensibly reduces the overhead and the resource contention
          occurring when a VM updates its own page tables. It is extremely
          unlikely that the host OS runs a workload which requires or
          benefits from using (Transparent) Huge Pages. Having them on the
          host may even negatively affect performance if the THP daemon
          interferes with the VMs' execution, consuming CPU time and
          causing latencies. Therefore, it is advised to disable THP on
          KVM, by adding the following host kernel command-line
          option:</p><pre class="screen">transparent_hugepage=never</pre><p>Another option is executing the following at runtime:</p><pre class="screen">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</pre><p>For being able to use 1 GB Huge Pages as backing memory of
          KVM guests, such pages need to be allocated on the host, by the
          host OS. It is best to do that at boot time, as follows:</p><pre class="screen">default_hugepagesz=1GB hugepagesz=1GB hugepages=&lt;number of hugepages&gt;</pre><p>The value for &lt;number of hugepages&gt; can be computed by
          taking the amount of memory devoted to VMs, and dividing it by
          the page size (1 GB). For example, the host in the example
          scenario has 256 GB RAM; take out 5 percent ~= 26 GB, and the
          number you get is 230 x 1 GB Huge Pages.</p><p>On Xen, none of the above actions is necessary. Dom0 is a
          paravirtualized guest, for which Huge Pages support is not
          present. On the other hand, memory used by the hypervisor, and
          memory allocated for HVM VMs, uses Huge Pages as much as possible
          by default, so no explicit tuning is needed.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-automatic-numa-balancing"></a>Automatic NUMA Balancing</h4></div></div></div><p>On Xen, <span class="italic">Automatic NUMA Balancing
            (NUMAB)</span> for the host OS should be disabled. Dom0 is
          a paravirtualized guest without a (virtual) NUMA topology, thus
          it would be totally useless. Since the Dom0 OS does not detect
          any NUMA topology, NUMAB will stay off, without any intervention
          needed.</p><p>On KVM, NUMAB can be useful and improve throughput. For
          example, this can be the case in dynamic virtualization
          scenarios, where VMs are created, destroyed and re-created
          relatively quickly, and without statically partitioning and
          pre-assigning resources (pCPUs and memory) to them. However,
          latency is introduced, and NUMAB operation can interfere, and
          cause performance degradation with VMs not needing and not using
          its services. Furthermore, since this paper focuses on careful
          and tailored resource pre-allocation, it is recommended to switch
          NUMAB off. This can be done by adding the following parameter to
          the host kernel command line:</p><pre class="screen">numa_balancing=disable</pre><p>If anything changes and the system is repurposed to achieve
          different goals, NUMAB can be enabled on-line with the
          command:</p><pre class="screen">echo 0 &gt; /proc/sys/kernel/numa_balancing</pre></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-services-daemons-power"></a>Services, Daemons and Power Management</h4></div></div></div><p>The service daemons that have been discussed already in the
          first part of the paper also run on the host OS of a
          virtualization system. For them, the same considerations that
          were made there apply here.</p><p>For example, <em class="parameter"><code>tuned</code></em> should either not
          be used, or the profile should be set to one that does not
          implicitly put the CPUs in polling mode. Both
          throughput-performance and virtualization-host profiles from SUSE
          Linux Enterprise Server 12 SP3 are OK, from this point of view,
          as neither of them touches
            <code class="filename">/dev/cpu_dma_latency</code>.
            <span class="package">irqbalance</span> can be a source of latency, for
          no significant performance improvement. Thus the suggestion is
          again to disable it (but then, IRQs may need to be manually bound
          to the appropriate CPUs, considering the IO topology).</p><p>As far as power management is concerned, the
            <span class="package">cpufreq</span> governor can either be kept as it is
          by default, or switched to <em class="parameter"><code>performance</code></em>,
          following the previous advice, based on the nature of the
          workloads of interest.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Power Management</h3><p>For anything that concerns power management, on KVM,
            changing the tuned profile, or using
              <span class="package">cpupower</span>, from the host OS will have the
            same effect described in the first part of the paper. On Xen,
            however, CPU frequency scaling is enacted by the hypervisor. It
            can be controlled from within Dom0, by using a different tool,
            called <span class="package">xenpm</span>, like in the example
            below:</p><pre class="screen">xenpm set-scaling-governor performance</pre></div></div></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title"><a id="sec-resource-allocation-tuning-vms"></a>Resource Allocation and Tuning of the VMs</h3></div></div></div><p>For instructions of how to create an initial VM configuration,
        run the VM, and install a guest OS, refer to the SUSE documentation
        at <a class="link" href="https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-vt-installation.html#sec-vt-installation-kvm" target="_top">https://documentation.suse.com/sles/12-SP4/html/SLES-all/cha-vt-installation.html#sec-vt-installation-kvm</a>
        .</p><p>From a VM configuration perspective, the two most important
        factors for achieving top performance on CPU and memory bound
        workloads are:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Placement of the VM on top of the host resources</p></li><li class="listitem"><p>Enlightenment of the VM about its own topology</p></li></ol></div><p>The former factor is critical. For example, with two VMs, one
        should be run on each socket to maximize CPU and memory access
        parallelism. The latter also helps, in particular with big VMs,
        which span more than one of the EPYC NUMA nodes. When the VM is
        made aware of its own virtual NUMA topology, all the tuning actions
        described in the first part of this paper become applicable to the
        workloads the VM is running.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Additional Tuning Factors</h3><p>Even with these two factors being the most important aspects
          of the VM configuration tuning process, there are additional
          factors which should be considered.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-placement-vms"></a>Placement of VMs</h4></div></div></div><p>When a VM is created, memory is allocated on the host to act
          as its virtual RAM. This is generally something that happens at
          VM boot time. This either cannot be changed at all, or cannot be
          changed without a price. Therefore, it is of paramount importance
          to get this initial placement correct. Both Xen and KVM can make
            <span class="quote">“<span class="quote">educated guesses</span>”</span> on what a good placement might
          be. However, this paper provides advise only on how to <span class="strong"><strong>manually</strong></span> achieve the best possible
          placement, considering EPYC specific characteristics.</p><p>Where the vCPUs will run (this means, on what pCPUs) is also
          decided at VM creation time. Contrarily to memory, it is less of
          a problem to change this when the VM is running, but it is still
          better to start the VM directly with good vCPU placement. This is
          particularly true on Xen, where vCPU placement actually drives
          and controls memory placement.</p><p>Since this paper does not consider oversubscribed scenarios,
          this form of static resource assignment is particularly
          effective. However, similar principles apply even when
          oversubscription is present.</p><p>Placement of memory happens by means of the &lt;numatune&gt;
          XML element:</p><pre class="screen">
  &lt;numatune&gt;
    &lt;memory mode='strict' nodeset='0-7'/&gt;
    &lt;memnode cellid='0' mode='strict' nodeset='0'/&gt;
    &lt;memnode cellid='1' mode='strict' nodeset='1'/&gt;
    …
  &lt;/numatune&gt;
</pre><p>The parameter <em class="parameter"><code>'strict'</code></em> enforces the
          memory to be allocated where it is specified. A cell is a virtual
          NUMA node, with <em class="parameter"><code>cellid</code></em> being its ID, and
            <em class="parameter"><code>nodeset</code></em> telling on what host physical
          NUMA node its memory must be put. For NUMA-unaware VMs, this can
          still be used, but it will have only one
            <em class="parameter"><code>&lt;memnode&gt;</code></em> element.</p><p>Placement of vCPUs happens via the
            <em class="parameter"><code>&lt;cputune&gt;</code></em> element, as in the
          example below:</p><pre class="screen">
  &lt;vcpu placement='static'&gt;96&lt;/vcpu&gt;
  &lt;cputune&gt;
    &lt;vcpupin vcpu='0' cpuset='1'/&gt;
    &lt;vcpupin vcpu='1' cpuset='65'/&gt;
    &lt;vcpupin vcpu='2' cpuset='2'/&gt;
    &lt;vcpupin vcpu='3' cpuset='66'/&gt;
    &lt;vcpupin vcpu='4' cpuset='3'/&gt;
    …
  &lt;/cputune&gt;
</pre><p>In this example, in the
            <em class="parameter"><code>&lt;vcpupin&gt;</code></em> elements,
            <em class="parameter"><code>vcpu</code></em> is the vCPU ID, and
            <em class="parameter"><code>cpuset</code></em> defines on what host physical CPU
          it should be bound to. </p><p>When <span class="quote">“<span class="quote">pinning</span>”</span> vCPUs to pCPUs, it is generally
          wise to put adjacent vCPU IDs (like vCPU 0 and vCPU 1) on actual
          host hyperthread siblings (like pCPU 1 and pCPU 65) on the test
          server. QEMU uses a static hyperthread sibling CPU ID assignment.
          Thus, by doing as described, at the end the virtual hyperthread
          siblings will run on real hardware hyperthread siblings.</p><p>The following paragraphs will address several scenarios with
          varying number and sizes of VMs. All the examples detailed in
          this section refer to the topology shown in <a class="xref" href="sec-epyc-topology.html#fig-epyc-topology" title="Figure 1. EPYC Topology">Figure 1, “EPYC Topology”</a>.</p><h5><a id="id2002"></a>
          <span class="italic">One Very Large VM</span>
        </h5><p>It is possible to use <span class="quote">“<span class="quote">just one</span>”</span> VM on the EPYC
          server. Reasons for this scenario include security/isolation,
          flexibility, high availability, and others. In these cases
          typically a single large VM would be used, almost as large as the
          host itself. Consider a VM with 96 vCPUs and 200 GB of RAM. That
          is a VM that spans multiple host NUMA nodes. It is recommended to
          create eight virtual NUMA nodes, that is as many as there are
          physical NUMA nodes, and divide the VM’s memory equally among
          them. The 96 vCPUs can be divided into 12 assigned to each node.
          It is also recommended to use full cores, this means: assign
          vCPUs 0 and 1 to Core P#1 in <a class="xref" href="sec-epyc-topology.html#fig-epyc-topology" title="Figure 1. EPYC Topology">Figure 1, “EPYC Topology”</a>,
          vCPUs 2 and 3 to Core P#2, vCPUs 4 and 5 to Core P#5. This
          configuration pins vCPUs 0 and 1 to pCPUs 0 and 64, vCPUs 2 and 3
          to pCPUs 1 and 65, etc.</p><p>Memory should be split equally among all 8 nodes, and a
          virtual topology will be provided to the guest OS of the VM.
          Using this setup, each of the VM’s vCPUs will access its own
          memory directly, and use InfinityFabric links to reach foreign
          memory, as it happens on the host. Workloads inside such a VM can
          be tuned exactly like they were running on a bare metal EPYC
          server (however on one with slightly fewer CPUs and less
          RAM).</p><p>The following example <span class="command"><strong>numactl</strong></span> output comes
          from a VM configured as explained:</p><pre class="screen">
available: 8 nodes (0-7)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11
node 0 size: 25118 MB
node 0 free: 25000 MB
node 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23
node 1 size: 25198 MB
node 1 free: 25116 MB
node 2 cpus: 24 25 26 27 28 29 30 31 32 33 34 35
node 2 size: 25198 MB
node 2 free: 25122 MB
node 3 cpus: 36 37 38 39 40 41 42 43 44 45 46 47
node 3 size: 25198 MB
node 3 free: 25106 MB
node 4 cpus: 48 49 50 51 52 53 54 55 56 57 58 59
node 4 size: 25198 MB
node 4 free: 25109 MB
node 5 cpus: 60 61 62 63 64 65 66 67 68 69 70 71
node 5 size: 25198 MB
node 5 free: 25122 MB
node 6 cpus: 72 73 74 75 76 77 78 79 80 81 82 83
node 6 size: 25198 MB
node 6 free: 25116 MB
node 7 cpus: 84 85 86 87 88 89 90 91 92 93 94 95
node 7 size: 25196 MB
node 7 free: 25111 MB
node distances:
node   0   1   2   3   4   5   6   7
  0:  10  20  20  20  20  20  20  20
  1:  20  10  20  20  20  20  20  20
  2:  20  20  10  20  20  20  20  20
  3:  20  20  20  10  20  20  20  20
  4:  20  20  20  20  10  20  20  20
  5:  20  20  20  20  20  10  20  20
  6:  20  20  20  20  20  20  10  20
  7:  20  20  20  20  20  20  20  10
</pre><p>This is analogous to the host topology already presented in
          the paper, with the only differences being the number and the IDs
          of the CPUs, and the nodes’ distance table. Unfortunately, the
            <span class="package">libvirt</span> version available in SUSE Linux
          Enterprise Server 12 SP3 does not allow to define virtual node
          distances (while later versions do).</p><p>See <a class="xref" href="sec-appendix-a.html" title="Appendix A">the section called “Appendix A”</a> for an (almost) complete
          VM configuration file.</p><h5><a id="id2015"></a>
          <span class="italic">Two Large VMs</span>
        </h5><p>When running two VMs with 48 vCPUs and 100 GB memory each,
          nearly the same configuration can be used, but each VM should be
          placed on one of the EPYC sockets. This means that each VM will
          span – both vCPU- and memory-wise – 4 NUMA nodes (and hence have
          4 virtual NUMA nodes). The reason behind locating one on each
          socket is that workloads running within each VM will not need to
          use the inter-socket interconnect, to access memory.</p><p>In this example scenario, the <span class="package">numactl</span>
          output looks as follows:</p><pre class="screen">
available: 4 nodes (0-3)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11
node 0 size: 25118 MB
node 0 free: 25026 MB
node 1 cpus: 12 13 14 15 16 17 18 19 20 21 22 23
node 1 size: 25198 MB
node 1 free: 25094 MB
node 2 cpus: 24 25 26 27 28 29 30 31 32 33 34 35
node 2 size: 25198 MB
node 2 free: 25084 MB
node 3 cpus: 36 37 38 39 40 41 42 43 44 45 46 47
node 3 size: 25196 MB
node 3 free: 25108 MB
node distances:
node   0   1   2   3
  0:  10  20  20  20
  1:  20  10  20  20
  2:  20  20  10  20
  3:  20  20  20  10
</pre><h5><a id="id2021"></a>
          <span class="italic">Four to Eight Medium-size VMs</span>
        </h5><p> The same principle adopted for two VMs is followed in a
          scenario with four VMs, with 24 vCPUs and 50 GB memory. In this
          case, VM1 should be put on nodes 0 and 1, VM2 on nodes 3 and 4,
          etc. Single VMs again span multiple (two, in this case) host NUMA
          nodes, but do not cross the socket boundary. Since they span two
          nodes, they benefit from being NUMA-aware. </p><p>In a scenario with eight VMs, with 12 vCPUs and 25 GB RAM
          each, each VM can be put on a single host NUMA node. In this
          case, therefore, there is no need for the VMs to be NUMA-aware.
          It is still helpful to let the guest OS know about the guest
          specific characteristics of the pCPU being used (cores, threads,
          etc), but it is less performance-critical (at least for memory
          intensive workloads).</p><p>The example below shows the <span class="package">numactl</span> output
          from one of these eight NUMA-unaware VMs:</p><pre class="screen">
available: 1 nodes (0)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 10 11
node 0 size: 25117 MB
node 0 free: 24888 MB
node distances:
node   0
  0:  10
</pre><h5><a id="id2028"></a>
          <span class="italic">Many <span class="quote">“<span class="quote">Micro</span>”</span>-VMs</span>
        </h5><p>When there is the need to have more than one VM per host NUMA
          node, the VMs will also not be NUMA-aware. If they have 4 vCPUs
          each, the best solution is to assign VM1 to Core P#0 and Core
          P#1, and VM2 to Core P#2 and Core P#3, on NUMA node 1, and do the
          same on the other nodes. That means VMs will use hyperthreading
          and, if possible, they should be made aware of this bit of
          topology information.</p><p>If they must have two vCPUs each, but they are still not more
          than 128 VMs, it is best to assign VM1 to Core P#0-PU P#0 and
          Core P1-PU P#2, then VM2 to Core P#2-PU P#4 and Core P3-PU P#6,
          on node 1 (and so on for the other nodes). This means only one of
          the hyperthread siblings on each core is used. The other sibling
          can be left idle, or be used for the IO of the VMs themselves (by
          giving them to the host OS, and using them for running either the
          emulator’s IO threads, on KVM, or the IO back-ends, on
          Xen).</p><p>When using 128 VMs, the recommendation is to use single cores
          for each VMs (although, this time, VM1 should be assigned to Core
          P#0, VM2 to Core P#2, etc.).</p><p>It should be avoided to have vCPUs from different VMs running
          on two hyperthread siblings. This is supported and works, but is
          not ideal for performance, especially from a consistency point of
          view, as the <span class="quote">“<span class="quote">speed</span>”</span> of the vCPUs of one VM will
          depend on what the vCPUs of another VM are doing. It is also a
          less secure setup, as running on hyperthread siblings may make it
          easier to enact cross-VM side channel attacks.</p><p>As far as memory is concerned, it is recommended that the
          memory of the VMs that are assigned to a NUMA node resides on
          that same node.</p><h5><a id="id2037"></a>
          <span class="italic">Oversubscription</span>
        </h5><p>If an oversubscription scenario is wanted, exclusive 1-to-1
          vCPU to pCPU assignment may be not ideal. In this case, it is in
          generally better to let the hypervisor scheduler take advantage
          of any idle interval on a wide range of pCPUs, and use that to
          execute as many vCPUs as possible for as long as it can. However,
          leaving all the vCPUs of all the VMs completely free to run on
          any pCPU might be equally bad, especially on EPYC. That may
          quickly put the system in a state where a lot of VMs mostly
          access memory from remote NUMA nodes, with regard to where their
          vCPUs are running.</p><p>In this case the recommendation is to try to partition the
          overall workload. This can be done by assigning groups of VMs to
          single nodes, or to the smallest possible set of nodes, in a way
          that takes load into account. This happens for example by
          avoiding to put all the CPU intensive VMs on the same node, or by
          avoiding to overload a node and leaving others lightly loaded or
          idle, etc.</p><p>This grouping of VMs on (a set of) nodes can still be done
          with vCPUs affinity. But there are also other mechanisms,
          specifically designed for doing <span class="quote">“<span class="quote">pooling</span>”</span>, such as
            <span class="package">cgroups</span> (on KVM) and
            <span class="package">cpupools</span> (on Xen). On Xen, there is also a
          feature called <span class="italic">soft vCPU
            affinity</span>, which can be used together with
            <span class="quote">“<span class="quote">traditional</span>”</span> vCPU affinity (also called <span class="italic">hard vCPU affinity</span>) as a finer grained
          and more powerful way of controlling resource allocation in such
          a scenario.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-enlightment-vms"></a>Enlightenment of the VMs</h4></div></div></div><p><span class="quote">“<span class="quote">Enlightenment</span>”</span> means letting the guest OS know as
          many details as possible of the (virtual) topology of the VM. Of
          course, this brings performance improvements only if such
          topology is properly and effectively mapped on host resources,
          and if the mapping is stable.</p><p>To ensure the VM has a vCPU topology, use the
          following:</p><pre class="screen">
  &lt;cpu mode='host-passthrough'&gt;
    &lt;topology sockets='2' cores='24' threads='2'/&gt;
    &lt;numa&gt;
      &lt;cell id='0' cpus='0-11' memory='26214400' unit='KiB'/&gt;
      &lt;cell id='1' cpus='12-23' memory='26214400' unit='KiB'/&gt;
      &lt;cell id='2' cpus='24-35' memory='26214400' unit='KiB'/&gt;
      …
    &lt;/numa&gt;
  &lt;/cpu&gt;
</pre><p>The <em class="parameter"><code>&lt;topology&gt;</code></em> element
          specifies the CPU characteristics, while each
            <em class="parameter"><code>&lt;cell&gt;</code></em> element defines one
          virtual NUMA node.</p><p>The following example (available on KVM only) is also useful,
          especially for VMs that span multiple host NUMA nodes, but in
          general every time that vCPUs are pinned to pCPUs that share a
          cache layer:</p><pre class="screen">
  &lt;domain type='kvm' xmlns:qemu='http://libvirt.org/schemas/domain/qemu/1.0'&gt;
    …
    &lt;qemu:commandline&gt;
      &lt;qemu:arg value='-cpu'/&gt;
      &lt;qemu:arg value='host,migratable=off,+invtsc,l3-cache=on'/&gt;
    &lt;/qemu:commandline&gt;
  &lt;/domain&gt;
</pre><p>The element <em class="parameter"><code>l3-cache=on</code></em> may
          significantly reduce resource contention within the VM, when the
          guest OS scheduler wants to wake up a task (while
            <em class="parameter"><code>migratable=off</code></em> is necessary for QEMU to
          preserve the other passed flags).</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-memory-backing"></a>Memory Backing</h4></div></div></div><p>The VMs need to be told to use the huge pages that were
          reserved for them. To effectively use 1 GB huge pages, the amount
          of memory each VM is given should be a multiple of 1 GB. Also,
            <span class="italic">Kernel Same Page Merging
            (KSM)</span> should be disabled. This is done as
          follows:</p><pre class="screen">
    &lt;memory unit='KiB'&gt;&lt;memory in KB&gt;&lt;/memory&gt;
      &lt;memoryBacking&gt;
        &lt;hugepages&gt;
          &lt;page size='1048576' unit='KiB'/&gt;
        &lt;/hugepages&gt;
        &lt;nosharepages/&gt;
      &lt;/memoryBacking&gt;
  </pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Huge Pages on Xen</h3><p>On Xen, for HVM guests, huge pages are used by default, so
            the <em class="parameter"><code>&lt;memoryBacking&gt;</code></em> element is
            technically not necessary.</p></div></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-no-ballooning"></a>No Ballooning</h4></div></div></div><p>To get the full benefit of using huge pages, memory
          ballooning must be disabled. If the ballooning driver is not
          huge-pages-aware, using it would split the pages and fragment
          memory. Disable memory ballooning as follows :</p><pre class="screen">&lt;currentMemory unit='KiB'&gt;&lt;memory in KiB&gt;&lt;/currentMemory&gt;</pre><p>Specify the same amount of memory as in the
            <em class="parameter"><code>&lt;memory&gt;</code></em>element and never change
          the memory of the VM at runtime.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-vm-transparent-huge-pages"></a>(Transparent) Huge Pages</h4></div></div></div><p>If huge pages are used for allocating the VMs’ memory on the
          host, they can also be used inside the VMs, either explicitly, or
          via THP. Whether that helps performance is workload dependent.
          The analysis and the considerations made in the first part of the
          paper about using (T)HP on bare metal can also be applied
          here.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-vm-automatic-numa-balancing"></a>Automatic NUMA Balancing</h4></div></div></div><p>Similarly to THP, if the VM is NUMA-aware, NUMAB can be used
          inside of it to boost the performance of NUMA-unaware
          workloads.</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-vm-services-daemons"></a>Services and Daemons</h4></div></div></div><p>The <span class="package">irqbalance</span> tool can be a source of latency
          inside of the VM, because of the way it uses the
            <code class="filename">/proc/interrupts</code> interface. For workloads
          that are particularly sensitive to latency, consider disabling it
          within the VMs (of course by taking the appropriate alternative
          measures, like binding IRQs, if necessary).</p></div><div class="sect3"><div class="titlepage"><div><div><h4 class="title"><a id="sec-emulator-disaggregation"></a>Emulator IO Threads / Disaggregation</h4></div></div></div><p>IO for the VMs is carried out either by emulators, or by the
          so-called <span class="emphasis"><em>back-ends</em></span> of paravirtualized
          drivers. Both the IO threads of the emulators, and the back-ends
          are user or kernel threads running in the host OS. As such, they
          can run on specific subsets of the host OS’ CPUs (Dom0’s virtual
          CPUs’, in the case of Xen). For example, a one vCPU VM can have
          its vCPU bound to a hyperthread sibling, while the IO threads can
          be bound to the other sibling. Considering that a common
          execution pattern will be for the vCPU to be idle, when the IO
          threads are busy, this setup maximizes the exploitation of
          hardware resources.</p><p>On Xen, there is also the possibility of setting up driver
          domains. These are special guests which act as back-ends of a
          particular IO device for one or more VMs. In case they are used,
          make sure that such guests run close enough to both the hardware
          they are providing their abstraction for, and the VMs that are
          servicing.</p></div></div><div class="sect2"><div class="titlepage"><div><div><h3 class="title"><a id="sec-virtualization-test-workload-stream"></a>Test Workload: STREAM</h3></div></div></div><p>To show the validity of some of the tuning advise given, the
        STREAM benchmark is used again.</p><h4><a id="id2096"></a>
        <span class="italic">Test Scenario: One Large VM</span>
      </h4><p>Figure 4 shows the bandwidth achieved by STREAM, using a single
        thread, on the host and inside one large VM, in the following
        configurations:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>No topology: the VM is not provided any virtual NUMA or CPU
            topology, nor are its memory and vCPUs assigned to host nodes
            and pCPUs</p></li><li class="listitem"><p>Topology: the VM is provided the virtual NUMA and CPU
            topology described in the above section, but still no mapping
            and pinning of memory and vCPUs</p></li><li class="listitem"><p>Topology Tuned: the VM is provided its topology, and memory
            is allocated and vCPUs are pinned as recommended in the tuning
            section</p></li></ul></div><div class="figure"><a id="fig-stream-single"></a><p class="title"><strong>Figure 4. STREAM Bandwidth - Single Thread in One VM</strong></p><div class="figure-contents"><div class="mediaobject"><table border="0" summary="manufactured viewport for HTML img" style="cellpadding: 0; cellspacing: 0;" width="80%"><tr><td><img src="images/amd-epyc-dario-figure-4-single.png" width="100%" alt="STREAM Bandwidth - Single Thread in One VM" /></td></tr></table></div></div></div><br class="figure-break" /><p>It appears evident how resource allocation is critical, for
        achieving good performance inside of the VM. When mapping VM
        resources on host resources as recommended, almost the same results
        are reached from within the VM, as obtained on the host.</p><p>Figure 5 shows the same setup, but when 16 threads are
        used.</p><div class="figure"><a id="fig-stream-16threads"></a><p class="title"><strong>Figure 5. STREAM Bandwidth - 16 Threads in One VM</strong></p><div class="figure-contents"><div class="mediaobject"><table border="0" summary="manufactured viewport for HTML img" style="cellpadding: 0; cellspacing: 0;" width="80%"><tr><td><img src="images/amd-epyc-dario-figure-5-16threads.png" width="100%" alt="STREAM Bandwidth - 16 Threads in One VM" /></td></tr></table></div></div></div><br class="figure-break" /><p>In this case, providing the VM with a meaningful topology
        already improves the performance. However, the result is still far
        from ideal, and good results are reached only when doing both
        topology enlightenment and proper placement of the VM.</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title"><span class="quote">“<span class="quote">Copy</span>”</span>in Figure 5</h3><p>With full tuning applied, we expected results matching the
          ones on the host. That was the case for <span class="quote">“<span class="quote">Scale</span>”</span>,
            <span class="quote">“<span class="quote">Add</span>”</span> and <span class="quote">“<span class="quote">Triad</span>”</span>.
            <span class="quote">“<span class="quote">Copy</span>”</span>, however, is implemented using glibc's
            <span class="package">memcpy()</span> which, when running on the host, is
          optimized with non-temporal store and prefetch instructions. In
          the VM, this does not happen because the heuristics that enables
          the use of those instructions does not trigger. This happens
          because the VM does not have any information available about how
          many and which logical CPUs share the L3 caches (which is what
          drives the heuristics). At the time of writing this paper, there
          is no way to let the VM have this information. SUSE is internally
          tracking this issue (partners can look up bug #1091081). When
          this is resolved, the performance of the <span class="quote">“<span class="quote">Copy</span>”</span>
          operation in a VM should reach the level of its performance on
          the host.</p></div><h4><a id="id2133"></a>
        <span class="italic">Test Scenario: Two Large VMs</span>
      </h4><p>Figure 6 shows how effective it is, when using two large VMs,
        to place them on separate sockets, as recommended above:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>VM1 alone: is the throughput achieved when running
              <span class="strong"><strong>only one</strong></span> of the two
            VMs</p></li><li class="listitem"><p>Both, VM1: is the throughput achieved on VM1, when running
            both the VMs concurrently</p></li><li class="listitem"><p>Both, VM2: is the throughput achieved on VM2, when running
            both the VMs concurrently</p></li><li class="listitem"><p>Both, VM1+VM2: is the aggregate throughput, that is, the
            sum of the throughput achieved on VM1 and on VM2 (when running
            both of them concurrently)</p></li></ul></div><p>In this case, the VMs have 48 vCPUs (each). Note how, based on
        the recommended tuning:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>performance achieved in both the VMs, when they are running
            concurrently, is the same as when only one of them is running
            alone;</p></li><li class="listitem"><p>the aggregate throughput is, on Triad, 194 GB/s; on the host
            and on only one large VM, it was 192 GB/s.</p></li></ul></div><div class="figure"><a id="fig-stream-2vm16threads"></a><p class="title"><strong>Figure 6. STREAM Bandwidth - 16 Threads in Two VMs</strong></p><div class="figure-contents"><div class="mediaobject"><table border="0" summary="manufactured viewport for HTML img" style="cellpadding: 0; cellspacing: 0;" width="80%"><tr><td><img src="images/amd-epyc-dario-figure-6-2vms16threads.png" width="100%" alt="STREAM Bandwidth - 16 Threads in Two VMs" /></td></tr></table></div></div></div><br class="figure-break" /><h4><a id="id2159"></a>
        <span class="italic">Test Scenario: Four to Eight Medium-Size
          VMs</span>
      </h4><p>Finally, Figure 7 shows again the effectiveness of carefully
        tuned resource allocation, this time on NUMA-unaware VMs. For this
        experiments, two VMs are used, each with 12 vCPUs and 25 GB memory.
        There are only two VMs used for simplicity, but the test hardware
        used could accommodate eight of them (without violating the
        recommendation of leaving at least one core on each node for the
        host OS). In this case, there is no virtual NUMA topology to
        construct for the VMs, and only 8 threads are used:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>VM1, unpinned: is the throughput achieved on VM1 running
            alone, when the VM’s vCPUs and memory are not pinned to the
            host resources</p></li><li class="listitem"><p>VM1, pinned: is the throughput achieved on VM1 running
            alone, when the VM’s vCPUs and memory are pinned to the host
            resources</p></li><li class="listitem"><p>VM1+VM2, unpinned: is the aggregate throughput reached
            together by VM1 and VM2, both not pinned in any way to the
            host</p></li><li class="listitem"><p>VM1+VM2, pinned: is the aggregate throughput reached
            together by VM1 and VM2, when both are pinned to the host
            resources</p></li></ul></div><p>In the <span class="quote">“<span class="quote">pinned</span>”</span> cases, the VMs are assigned to one
        NUMA node each, from different sockets. It is again evident how
        much reasonable placement of VM resources helps performance, even
        in case of NUMA-unaware VMs.</p><div class="figure"><a id="fig-stream-8threads"></a><p class="title"><strong>Figure 7. STREAM Bandwidth - 8 Threads in Two VMs</strong></p><div class="figure-contents"><div class="mediaobject"><table border="0" summary="manufactured viewport for HTML img" style="cellpadding: 0; cellspacing: 0;" width="80%"><tr><td><img src="images/amd-epyc-dario-figure-7-8threads.png" width="100%" alt="STREAM Bandwidth - 8 Threads in Two VMs" /></td></tr></table></div></div></div><br class="figure-break" /></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="sec-candidate-workloads.html">Prev</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="sec-conclusion.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Candidate Workloads </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> Conclusion</td></tr></table></div></body></html>
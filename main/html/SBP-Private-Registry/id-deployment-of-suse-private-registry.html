<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Deployment of SUSE Private Registry</title><meta name="generator" content="DocBook XSL Stylesheets V1.79.2" /><style type="text/css">
body { background-image: url('static/images/draft.png');
       background-repeat: no-repeat;
       background-position: top left;
       /* The following properties make the watermark "fixed" on the page. */
       /* I think that's just a bit too distracting for the reader... */
       /* background-attachment: fixed; */
       /* background-position: center center; */
     }</style><link rel="home" href="index.html" title="SUSE Private Registry Powered by Harbor 2.1" /><link rel="up" href="index.html" title="SUSE Private Registry Powered by Harbor 2.1" /><link rel="prev" href="high-availability.html" title="High Availability" /><link rel="next" href="id-deployment-in-an-air-gapped-environment.html" title="Deployment in an Air-Gapped Environment " /></head><body onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Deployment of SUSE Private Registry</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="high-availability.html">Prev</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="id-deployment-in-an-air-gapped-environment.html">Next</a></td></tr></table><hr /></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="id-deployment-of-suse-private-registry"></a>Deployment of SUSE Private Registry</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-preparation"></a>Preparation</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Ensure you have <code class="literal">kubectl</code> and <code class="literal">helm</code> v3 installed and check that you have access to the target Kubernetes cluster where SUSE Private Registry will be installed.</p></li><li class="listitem"><p>Decide between using a Kubernetes Ingress or just a Load Balancer to expose the SUSE Private Registry services.</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>If Kubernetes Ingress is the chosen option, ensure that:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: square; "><li class="listitem"><p>You have an Ingress Controller set up in the target Kubernetes cluster.</p></li><li class="listitem"><p>You prepare two resolvable FQDN values:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>One for the Harbor UI/API.</p></li><li class="listitem"><p>One for the Notary API (only if <code class="literal">Notary</code> will be enabled).</p></li></ul></div></li></ul></div></li><li class="listitem"><p>If using just a LoadBalancer, ensure that you have one of the following:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: square; "><li class="listitem"><p>A predefined external IP address that can be associated with the Load Balancer service used to expose the SUSE Private Registry services.</p></li><li class="listitem"><p>An FQDN value that, later on, can be mapped in the external DNS to the external IP address dynamically allocated to the Load Balancer service during installation.</p></li></ul></div></li></ul></div></li><li class="listitem"><p>For the Harbor UI/API and Notary API, choose between using auto-generated TLS certificates or providing your own custom TLS certificates. If using your own, have the certificates ready.</p></li><li class="listitem"><p>Choose the persistent storage back-end to store OCI artifacts: a Kubernetes <code class="literal">StorageClass</code>, or one of the external storage services available from public-cloud providers.</p></li><li class="listitem"><p>Verify that the target Kubernetes cluster provides the required <code class="literal">StorageClass</code>(es). A <code class="literal">StorageClass</code> with <code class="literal">ReadWriteMany</code> access mode is required to fully enable  and scalability for the <code class="literal">registry</code> SUSE Private Registry component, unless an external storage service is used to store OCI artifacts.</p></li><li class="listitem"><p>Choose between using an internal or external database service.</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>The internal database service does not support high availability and scalability, and is therefore <span class="strong"><strong>not recommended for production</strong></span>.</p></li><li class="listitem"><p>If you use an external database service instead, prepare it separately beforehand.</p></li></ul></div></li><li class="listitem"><p>Choose between using an internal or external Redis service. Similarly to the database:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>The internal Redis service does not support high availability and scalability and <span class="strong"><strong>is not recommended for production</strong></span>.</p></li><li class="listitem"><p>Similarly, if you will use an external, public-cloud-managed Redis service, you must prepare it separately beforehand.</p></li><li class="listitem"><p>If you prefer to use the SUSE <code class="literal">redis-ha</code> operator service, installation instructions are included in the SUSE Private Registry installation steps covered this section.</p></li></ul></div></li><li class="listitem"><p>Optionally, prepare a GitHub personal authentication token, in order to prevent rate-limiting problems when <code class="literal">trivy</code> downloads its vulnerability database.</p></li><li class="listitem"><p>Determine resource requests and limits based on your Kubernetes cluster setup.</p></li><li class="listitem"><p>Optionally, prepare the Service Accounts to use for Harbor components.</p></li></ul></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-installation-steps"></a>Installation Steps</h3></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Download the Helm chart from the official SUSE repository:</p><pre class="screen">export HELM_EXPERIMENTAL_OCI=1
# download a chart from public registry
helm chart pull registry.suse.com/harbor/harbor:1.5
# export the chart to local directory
helm chart export registry.suse.com/harbor/harbor:1.5</pre></li><li class="listitem"><p>Make sure <code class="literal">KUBECONFIG</code> is set correctly</p><p>When installing on SUSE CaaS Platform, it is expected that the <code class="literal">KUBECONFIG</code> environment variable is set correctly pointing to the Kubernetes cluster.</p><p>When installing into hosted Kubernetes clusters such as EKS or AKS, configuration must be fetched first so the following <code class="literal">kubectl</code> and helm commands work correctly.</p><p>For AKS, it is possible to use the <code class="literal">az</code> command line tool to get the <code class="literal">kubeconfig</code>:</p><pre class="screen">az aks get-credentials --resource-group &lt;azure-resource-group&gt; --name &lt;aks-cluster-name&gt; --file kubeconfig.yaml
export KUBECONFIG=&lt;full path to kubeconfig.yaml&gt;</pre><p>For EKS, the <code class="literal">aws</code> command line tool can be used to generate the <code class="literal">kubeconfig</code>:</p><pre class="screen">aws eks --region &lt;region-code&gt; update-kubeconfig --name &lt;eks-cluster_name&gt; --kubeconfig kubeconfig.yaml
export KUBECONFIG=&lt;full path to kubeconfig.yaml&gt;</pre></li><li class="listitem"><p>Prepare a <code class="literal">harbor-values.yaml</code> file to specify custom SUSE Private Registry configuration values</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>The default configuration provided with the SUSE Private Registry helm chart is not suited for production use!</p><p>A separate YAML file (referred to as the <code class="literal">harbor-values.yaml</code> file in the following sections) needs to be populated with customized configuration values to be used during installation.
The exact configuration options that can be customized, and the values that they can take, are covered in detail in the next installation steps.</p></div><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Tip</h3><p>The full list of configuration options and default values that can be overridden in <code class="literal">harbor-values.yaml</code> is included in the helm chart itself, and can be viewed in YAML format by running the following command:</p><pre class="screen">helm show values harbor</pre><p>It can also be used as a YAML template for configuration values that need to be customized, although it is recommended to keep only the configuration options that are changed from their default values in <code class="literal">harbor-values.yaml</code>, to allow default configuration changes to be introduced during upgrades.</p></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>The <code class="literal">harbor-values.yaml</code> file prepared and used during installation is the source of truth for the SUSE Private Registry configuration.</p><p>It will also be required for some administrative operations, such as subsequent configuration changes and upgrades.
Make sure to preserve this file in a safe place, preferably under version control, and to update it with every configuration change that is subsequently made to the deployed SUSE Private Registry instance.</p></div></li><li class="listitem"><p>(Optional) Disable unnecessary components</p><p>By default, SUSE Private Registry has all supported components enabled. Some components may be disabled in the configuration, if they are not required:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p><code class="literal">trivy</code> - disable if you do not require the security-vulnerability-scanning feature.</p></li><li class="listitem"><p><code class="literal">notary</code> - disable if you do not require the artifact-signing feature.</p></li></ol></div><p>To disable unnecessary components, set the relevant configuration options to false in <code class="literal">harbor-values.yaml</code>:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">trivy:
  enabled: false
notary:
  enabled: false</pre><p>
</p></li><li class="listitem"><p>Configure a way to expose the SUSE Private Registry UI and public APIs</p><p>The default and recommended way to expose the SUSE Private Registry services to be consumed from outside the Kubernetes cluster is to use a Kubernetes Ingress.
This requires that a Kubernetes Ingress controller is already configured in your cluster and resolvable FQDNs to be prepared for the Harbor UI/API and the Notary API services (if enabled).
Alternatively, services may be exposed using a Kubernetes LoadBalancer instead.</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Expose SUSE Private Registry using a Kubernetes Ingress</p><p>This option assumes a Kubernetes Ingress Controller is already configured for your Kubernetes cluster, as described in the <a class="xref" href="requirements.html#requirements-ingress" title="Ingress">the section called “Ingress”</a> section.
Update <code class="literal">harbor-values.yaml</code> with the following configuration values:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
  # Set the way how to expose the service. Default value is "ingress".
  ingress:
    hosts:
      core: "&lt;core_fqdn&gt;"
      notary: "&lt;notary_fqdn&gt;"

# The external URL for Harbor core service. It is used to
# 1) populate the docker/helm commands showed on portal
# 2) populate the token service URL returned to docker/Notary client
#
# Format: protocol://domain[:port]. Usually:
# 1) if "expose.type" is "ingress", the "domain" should be
# the value of "expose.ingress.hosts.core"
#
# If Harbor is deployed behind the proxy, set it as the URL of proxy
externalURL: "https://&lt;core_fqdn&gt;"</pre><p>
</p><p>Replace <code class="literal">&lt;core_fqdn&gt;</code> and <code class="literal">&lt;notary_fqdn&gt;</code> values with the resolvable FQDN values that were prepared as detailed in the <a class="xref" href="requirements.html" title="Requirements">the section called “Requirements”</a> section.
If the Notary service was not enabled in the configuration, the <code class="literal">&lt;notary_fqdn&gt;</code> entry may be omitted.
The <code class="literal">harbor-values.yaml</code> configuration would look like this, if, for example, a public service like <a class="link" href="https://nip.io" target="_top">nip.io</a> was used to provide FQDNs:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
  ingress:
    hosts:
      core: harbor.10.86.0.237.nip.io
      notary: notary.10.86.0.237.nip.io
externalURL: "https://harbor.10.86.0.237.nip.io"</pre><p>
</p><p>Depending on which Kubernetes Ingress Controller is used, you may need to add additional annotations to the SUSE Private Registry Ingress configuration:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
  ingress:
	...
    annotations:
      # To be used for the nginx ingress on AKS:
      kubernetes.io/ingress.class: nginx
      # To be used for the ALB ingress on EKS:
      kubernetes.io/ingress.class: alb</pre><p>
</p></li><li class="listitem"><p>Expose SUSE Private Registry using a Kubernetes LoadBalancer</p><p>Update the <code class="literal">harbor-values.yaml</code> configuration file with the following configuration values:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
  type: loadBalancer
  loadBalancer:
    # Set the IP if the LoadBalancer supports assigning IP
    IP: ""

# The external URL for Harbor core service. It is used to
# 1) populate the docker/helm commands showed on portal
# 2) populate the token service URL returned to docker/Notary client
#
# Format: protocol://domain[:port]. Usually:
# 1) if "expose.type" is "ingress", the "domain" should be
# the value of "expose.ingress.hosts.core"
#
# If Harbor is deployed behind the proxy, set it as the URL of proxy
externalURL: "https://&lt;harbor_fqdn_or_ip_addr&gt;"</pre><p>
</p><p>You must set the <code class="literal">&lt;harbor_fqdn_or_ip_addr&gt;</code> value to an FQDN that can be resolved to the external IP address allocated to the Harbor Load Balancer service.
Alternatively, if the LoadBalancer solution used for the underlying Kubernetes distribution supports assigning an IP address beforehand, you can set both the <code class="literal">expose.loadBalancer.IP</code> configuration option and the <code class="literal">&lt;harbor_fqdn&gt;</code> value to a predefined external IP address.</p></li></ol></div></li><li class="listitem"><p>Configure external TLS and certificates</p><p>TLS certificates are required to secure access to the SUSE Private Registry services that are exposed for external consumption - the Harbor UI/API and the Notary API (if Notary is enabled).
These certificates may either be generated automatically during installation (default), or provided as Kubernetes secrets, or configured beforehand as the default TLS certificate for the Kubernetes Ingress Controller used to expose the services, as explained in the TLS Certificates requirements (<a class="xref" href="requirements.html#requirements-tls" title="TLS Certificates">the section called “TLS Certificates”</a>) section.</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Auto-generated certificates</p><p>This is the default helm chart setting. If an Ingress was used to expose the SUSE Private Registry services, the FQDN values configured for the ingress will be used to generate the TLS certificates automatically.
If using a LoadBalancer to expose the services instead of Ingress, please also set the <code class="literal">commonName</code> option to the pre-allocated external IP address or the FQDN value that will be resolved to it:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
..
  tls:
    enabled: true
    # The source of the tls certificate. Set it as "auto", "secret"
    # or "none" and fill the information in the corresponding section
    # 1) auto: generate the tls certificate automatically
    # 2) secret: read the tls certificate from the specified secret.
    # The tls certificate can be generated manually or by cert manager
    # 3) none: configure no tls certificate for the ingress. If the default
    # tls certificate is configured in the ingress controller, choose this option
    certSource: auto
    auto:
      # The common name used to generate the certificate, it's necessary
      # when the type isn't "ingress"
      commonName: "&lt;harbor_fqdn_or_ip_addr&gt;"</pre><p>
</p></li><li class="listitem"><p>Custom certificates</p><p>One or two custom certificates are required for exposed SUSE Private Registry services: one for the Harbor UI/API and another one for the Notary API (required only if Notary is enabled). The certificates need to reflect the FQDN values or external IP address values used at the previous step to configure the Kubernete Ingress or LoadBalancer service exposure settings. The helm chart also supports using a single certificate instead of two, as long as the CN or SAN certificate field values match both FQDNs. The certificates need to be supplied in the form of Kubernetes secrets:</p><pre class="screen">kubectl create secret tls -n registry &lt;harbor-tls-secret&gt; --key ${HARBOR_CERT_KEY_FILE} --cert ${HARBOR_CERT_FILE}
kubectl create secret tls -n registry &lt;notary-tls-secret&gt; --key ${NOTARY_CERT_KEY_FILE} --cert ${NOTARY_CERT_FILE}</pre><p>In case the certificate has intermediate CAs, you can bundle them into the CERT_FILE prior creating the secret, e.g.:</p><pre class="screen">cat $CERT_FILE $bundle_ca_file &gt; bundled_cert_file
kubectl create secret tls -n registry &lt;tls-secret&gt; --key ${KEY_FILE} --cert bundled_cert_file</pre><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
..
  tls:
    enabled: true
    # The source of the tls certificate. Set it as "auto", "secret"
    # or "none" and fill the information in the corresponding section
    # 1) auto: generate the tls certificate automatically
    # 2) secret: read the tls certificate from the specified secret.
    # The tls certificate can be generated manually or by cert manager
    # 3) none: configure no tls certificate for the ingress. If the default
    # tls certificate is configured in the ingress controller, choose this option
    certSource: secret
    secret:
      # The name of secret which contains keys named:
      # "tls.crt" - the certificate
      # "tls.key" - the private key
      secretName: "&lt;harbor-tls-secret&gt;"
      # The name of secret which contains keys named:
      # "tls.crt" - the certificate
      # "tls.key" - the private key
      # Only needed when the "expose.type" is "ingress".
      notarySecretName: "&lt;notary-tls-secret&gt;"</pre><p>
</p></li><li class="listitem"><p>Default Ingress certificate</p><p>If a default TLS certificate has been set up for the Kubernetes Ingress Controller earlier, as covered in the TLS Certificates section, certificates need not be explicitly supplied during the SUSE Private Registry installation. It is sufficient to set the <code class="literal">tls.certSource</code> option to <code class="literal">none</code>:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">expose:
..
  tls:
    enabled: true
    # The source of the tls certificate. Set it as "auto", "secret"
    # or "none" and fill the information in the corresponding section
    # 1) auto: generate the tls certificate automatically
    # 2) secret: read the tls certificate from the specified secret.
    # The tls certificate can be generated manually or by cert manager
    # 3) none: configure no tls certificate for the ingress. If the default
    # tls certificate is configured in the ingress controller, choose this option
    certSource: none</pre><p>
</p></li></ol></div></li><li class="listitem"><p>Configure internal TLS</p><p>In addition to securing external connections to exposed services, SUSE Private Registry also supports using TLS to secure internal communication between its components.
TLS certificates will be generated automatically for this purpose. Enabling internal TLS is optional, but highly recommended:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">internalTLS:
  enabled: true</pre><p>
</p><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>Internal TLS support does not yet cover the internal database and Redis services.</p></div><p>If SUSE Private Registry is deployed in K3s, note that unmodified Traefik (the default K3s ingress controller) will not work with automatically-generated certificates.
You must configure Traefik not to verify the backend SSL certificate (<code class="literal">insecureSkipVerify = true</code> option).
Learn how to modify Traefik settings in the <a class="link" href="https://rancher.com/docs/k3s/latest/en/helm/#customizing-packaged-components-with-helmchartconfig" target="_top">upstream documentation</a>.</p><p>For example, with K3s version 1.19 and newer, it is possible to use this kind of modification for the Traefik helm chart, then place it into the K3s manifest directory:</p><p><strong>traefik-config.yaml. </strong>
</p><pre class="screen">apiVersion: helm.cattle.io/v1
kind: HelmChartConfig
metadata:
  name: traefik
  namespace: kube-system
spec:
  valuesContent: |-
    ssl:
      insecureSkipVerify: true</pre><p>
</p></li><li class="listitem"><p>Configure Persistent Storage</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Configure Persistent Volumes</p><p>By default, persistent volumes are enabled for all stateful components of SUSE Private Registry.
However, a default <code class="literal">StorageClass</code> must be configured in the Kubernetes cluster to be able to provision volumes dynamically.
Alternatively, you can configure explicit <code class="literal">StorageClass</code> values for each component.</p><p>For each component that uses persistent storage, you can configure the following settings:</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p><code class="literal">storageClass</code>: Specify the "storageClass" used to provision the volume; if empty, the default <code class="literal">StorageClass</code> will be used (default: <code class="literal">empty</code>).</p></li><li class="listitem"><p><code class="literal">accessMode</code>: Volumes can be mounted on a container in any way supported by the storage provider. Valid values are:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p><code class="literal">ReadWriteOnce</code>: the volume can be mounted as read-write by a single container</p></li><li class="listitem"><p><code class="literal">ReadWriteMany</code>: the volume can be mounted as read-write by many containers. This is only required for the <code class="literal">registry</code> component, when configured in  mode and using a persistent volume to store OCI artifacts. If an external storage service is used to store OCI artifacts, or if a <code class="literal">ReadWriteMany</code> <code class="literal">StorageClass</code> isn’t available in your Kubernetes cluster, you should not use this value.
(default: <code class="literal">ReadWriteOnce</code>)</p></li></ol></div></li><li class="listitem"><p>size: the size of the volume to be provisioned (e.g. 5Gi for 5 gigabytes). Default values vary by component:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>registry: 5Gi</p></li><li class="listitem"><p>database: 1Gi</p></li><li class="listitem"><p>redis: 1Gi</p></li><li class="listitem"><p>trivy: 5Gi</p></li></ol></div><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>The default volume sizes provided by SUSE Private Registry are <span class="strong"><strong>not recommended for production</strong></span>.</p><p>We recommend careful planning and setting the volume sizes according to the expected usage.
Expanding in-use persistent-volume claims is only supported by some storage providers, and in some cases it will require restarting the pods, which will impact service availability.</p></div></li></ol></div><p>For configuring persistent storage, update <code class="literal">harbor-values.yaml</code> with the following configuration, and set the values accordingly:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">persistence:
  persistentVolumeClaim:
    registry:
      storageClass: ""
      accessMode: ReadWriteMany
      size:
    database:
      storageClass: ""
      size:
    redis:
      storageClass: ""
      size:
    trivy:
      storageClass: ""
      size:</pre><p>
</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Using external services</h3><p>The above settings will be ignored and may be omitted for components configured to use an external service (<code class="literal">database</code>, <code class="literal">redis</code>), and for the <code class="literal">registry</code> component when external storage is configured for OCI artifacts.</p></div><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>If a Kubernetes persistent volume is configured to store OCI artifacts instead of an external storage service, and if your Kubernetes cluster does not provide a <code class="literal">StorageClass</code> with <code class="literal">ReadWriteMany</code> access mode capabilities, then the <code class="literal">updateStrategy.type</code> option must set to <code class="literal">Recreate</code> in the <code class="literal">harbor-values.yaml</code> file. Otherwise, running <code class="literal">helm upgrade</code> to apply subsequent configuration changes or to perform upgrades will result in failure:</p><pre class="screen"># The update strategy for deployments with persistent volumes (registry): "RollingUpdate" or "Recreate"
# Set it as "Recreate" when "RWM" for volumes isn't supported
updateStrategy:
  type: Recreate</pre></div></li><li class="listitem"><p>Configure External Storage for OCI Artifacts</p><p>The default option for storing OCI artifacts, such as container images and helm charts, is using a persistent volume provided by the default <code class="literal">storageClass</code> of your Kubernetes cluster (as described on the previous section).
However, you can configure SUSE Private Registry to use an external storage solution such as Amazon S3 or Azure Blob Storage to store those artifacts.</p><p>For example, for Azure Blob Storage, you must pre-configure an Azure Storage Account and Azure Storage Container.
Using the <code class="literal">az</code> command line client, execute the following commands to create and fetch necessary resources:</p><pre class="screen">az storage account create --resource-group &lt;azure-resource-group&gt; --name &lt;azure-storage-account-name&gt;
az storage account keys list --resource-group &lt;azure-resource-group&gt; --account-name &lt;azure-storage-account-name&gt; -o tsv | head -n 1 | cut -f 3
az storage container create --account-name &lt;azure-storage-account-name&gt; --name &lt;azure-storage-container-name&gt; --auth-mode key</pre><p>Then, you must configure the "imageChartStorage" section in <code class="literal">harbor-values.yaml</code> as follows:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">persistence:
...
  imageChartStorage:
    type: azure
    azure:
      accountname: &lt;azure-storage-account-name&gt;
      accountkey: &lt;azure-storage-account-key&gt;
      container: &lt;azure-storage-container-name&gt;</pre><p>
</p><p>For Amazon S3, the process is similar. The <code class="literal">imageChartStorage</code> section in <code class="literal">harbor-values.yaml</code> will look like this:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">persistence:
...
  imageChartStorage:
    type: s3
      region: &lt;aws-region&gt;
      bucket: &lt;aws-s3-bucket-name&gt;
      accesskey: &lt;aws-account-access-key&gt;
      secretkey: &lt;aws-account-secret-key&gt;</pre><p>
</p></li></ol></div></li><li class="listitem"><p>(Optional) Configure a GitHub authentication token for Trivy</p><p>If the <code class="literal">Trivy</code> security vulnerability scanner service is enabled, we recommend <a class="link" href="https://docs.github.com/en/free-pro-team@latest/github/authenticating-to-github/creating-a-personal-access-token" target="_top">generating a GitHub personal authentication token</a> and supplying it in the <code class="literal">harbor-values.yaml</code> trivy configuration section, to prevent issues with <a class="link" href="https://docs.github.com/en/free-pro-team@latest/rest/reference/rate-limit" target="_top">the API rate-limiting that GitHub enforces on unauthenticated requests</a>:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">trivy:
  ...
  gitHubToken: "&lt;github-token-value&gt;"</pre><p>
</p></li><li class="listitem"><p>(Optional) Configure  parameters</p><p>By default, SUSE Private Registry uses a replica count (that is, the number of redundant pods providing the same service) value of 1 for all its components.
To have a highly-available deployment, configure a <code class="literal">ReplicaCount</code> value of at least 2 for enabled services in <code class="literal">harbor-values.yaml</code>:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">portal:
  replicas: 3
core:
  replicas: 3
# Only enabled when using a LoadBalancer instead of Ingress to expose services
nginx:
  replicas: 3
jobservice:
  replicas: 3
registry:
  replicas: 3
trivy:
  replicas: 3
notary:
  server:
    replicas: 3
  signer:
    replicas: 3</pre><p>
</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>You must have a Kubernetes <code class="literal">StorageClass</code> with <code class="literal">ReadWriteMany</code> access mode to enable  for the SUSE Private Registry <code class="literal">registry</code> component, when a Kubernetes persistent volume is used as the storage back-end for OCI artifacts.</p><p>If a <code class="literal">StorageClass</code> with <code class="literal">ReadWriteMany</code> access is not available for your Kubernetes cluster, setting the replica count to a value higher than 1 for the <code class="literal">registry</code> component will result in installation failure.
Furthermore, using <code class="literal">helm upgrade</code> to apply subsequent configuration changes or to perform upgrades will also result in failures without a <code class="literal">ReadWriteMany</code> access mode <code class="literal">StorageClass</code>.
To prevent that, ensure the <code class="literal">updateStrategy.type</code> option is set to <code class="literal">Recreate</code> in the <code class="literal">harbor-values.yaml</code> file:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen"># The update strategy for deployments with persistent volumes(registry): "RollingUpdate" or "Recreate"
# Set it as "Recreate" when "RWM" for volumes isn't supported
updateStrategy:
  type: Recreate</pre><p>
</p></div></li><li class="listitem"><p><a id="install-external-database"></a> (Optional) External Database Setup</p><p>We recommend an external database to deploy SUSE Private Registry in a fully highly-available and scalable setup.
This section assumes a managed PostgreSQL database instance has already been setup, either in Azure or AWS, as covered in the <a class="xref" href="requirements.html#requirements-external-postgres" title="External PostgreSQL Database">the section called “External PostgreSQL Database”</a>.</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Connect to an Azure PostgreSQL database</p><p>Add the following section to the <code class="literal">harbor-values.yaml</code> file and fill it with information reflecting the Azure PostgreSQL database instance previously configured as an external database:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">database:
  type: external
  external:
    host: &lt;database-fully-qualified-hostname&gt;
    port: "5432"
    username: &lt;admin-user&gt;@&lt;database-hostname&gt;
    password: &lt;admin-password&gt;
    # "disable" - No SSL
    # "require" - Always SSL (skip verification)
    # "verify-ca" - Always SSL (verify that the certificate presented by the
    # server was signed by a trusted CA)
    # "verify-full" - Always SSL (verify that the certification presented by the
    # server was signed by a trusted CA and the server host name matches the one
    # in the certificate)
    sslmode: "verify-full"</pre><p>
</p></li><li class="listitem"><p>Connect to an AWS PostgreSQL database</p><p>Add the following section to <code class="literal">harbor-values.yaml</code> and fill it with information reflecting the AWS PostgreSQL database instance previously configured as an external database:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">database:
  type: external
  external:
    host: &lt;database-fully-qualified-hostname&gt;
    port: "5432"
    username: &lt;admin-user&gt;@&lt;database-hostname&gt;
    password: &lt;admin-password&gt;
    # "disable" - No SSL
    # "require" - Always SSL (skip verification)
    # "verify-ca" - Always SSL (verify that the certificate presented by the
    # server was signed by a trusted CA)
    # "verify-full" - Always SSL (verify that the certification presented by the
    # server was signed by a trusted CA and the server host name matches the one
    # in the certificate)
    sslmode: "verify-full"</pre><p>
</p></li></ol></div></li><li class="listitem"><p><a id="install-redis-operator"></a> (Optional) Install Redis Operator</p><p>As mentioned above, Redis Operator provides High Availability to the Redis component of SUSE Private Registry. It can be installed into the same Kubernetes cluster as SUSE Private Registry. The installation of Redis operator is also done via a Helm chart, and must happen before the installation of SUSE Private Registry.</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Install Redis operator in its own Kubernetes namespace using the Helm chart:</p><pre class="screen">export HELM_EXPERIMENTAL_OCI=1
helm chart pull registry.suse.com/harbor/redis-operator:3.1
helm chart export registry.suse.com/harbor/redis-operator:3.1
kubectl create namespace redis-operator
helm -n redis-operator install harbor-redis ./redisoperator</pre></li><li class="listitem"><p>Configure <code class="literal">RedisFailover</code> object:</p><p>The Redis HA configuration needs to be specified in the <code class="literal">redisfailover</code> section of <code class="literal">harbor-values.yaml</code>.
The following is an example configuration:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">redisfailover:
  enabled: true
  name: harbor-redisfailover</pre><p>
</p></li><li class="listitem"><p>Configure SUSE Private Registry to be connected to the external Redis</p><p>Extend the <code class="literal">harbor-values.yaml</code> file with the configuration specified below.</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">redis:
  type: external
  external:
    addr: rfs-harbor-redisfailover:26379
    sentinelMasterSet: mymaster <a id="CO1-1"></a><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></pre><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO1-1"><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></a> </p></td><td valign="top" align="left"><p><code class="literal">mymaster</code> is a predefined value of redisfailover deployment and cannot be changed.</p></td></tr></table></div></li><li class="listitem"><p>(Optional) Set up own password</p><p>By default, if no secret and password are provided, the SUSE Private Registry Helm chart will generate a password. A custom password can also be provided:</p><pre class="screen">kubectl -n registry create secret generic redis-auth --from-literal=password="&lt;password-value&gt;"</pre><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">redis:
  type: external
  external:
    addr: rfs-harbor-redisfailover:26379
    sentinelMasterSet: mymaster
    password: &lt;password-value&gt;</pre><p>
</p></li><li class="listitem"><p>(Optional) Configure Redisfailover deployment</p><p>By default, the Redisfailover deployment has three sentinel replicas, three redis replicas, and will keep the data when the Helm chart is uninstalled. This behavior can be configured in the <code class="literal">redisfailover</code> section.</p></li></ol></div></li><li class="listitem"><p><a id="install-external-redis"></a> (Optional) External Redis Setup</p><p>We recommend an external Redis to deploy SUSE Private Registry in a fully highly-available and scalable setup.
When deployed in AKS or EKS, as an alternative to using the Redis Operator, SUSE Private Registry may instead be connected to a managed Redis instance running in public cloud.
This section assumes a managed Redis instance has already been setup, either in Azure or AWS, as covered in the External Redis requirements section.</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Connect to an Azure Cache for Redis instance</p><p>Add the following section to the <code class="literal">harbor-values.yaml</code> file and fill it with information reflecting the Azure Cache for Redis instance previously prepared.
As mentioned above in the <a class="xref" href="requirements.html#requirements-redis-azure" title="Azure Cache for Redis">the section called “Azure Cache for Redis”</a>, the address will have the form of <code class="literal">&lt;azure-redis-cache&gt;.redis.cache.windows.net</code>.</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">redis:
  type: external
  external:
    addr: "192.168.0.2:6379"
    password: access-key <a id="CO2-1"></a><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></pre><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO2-1"><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></a> </p></td><td valign="top" align="left"><p>Replace <code class="literal">access-key</code> with the access key retrieved after creating the Azure Cache for Redis instance.</p></td></tr></table></div></li><li class="listitem"><p>Connect to an Amazon ElastiCache Redis service</p><p>Add the following section to <code class="literal">harbor-values.yaml</code> and fill it with information reflecting the Amazon ElastiCache Redis instance that you previously prepared:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">redis:
  type: external
  external:
    addr: "192.168.0.2:6379"
    password: "" <a id="CO3-1"></a><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></pre><p>
</p><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO3-1"><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></a> </p></td><td valign="top" align="left"><p>Add password if configured manually (not the default) in AWS ElastiCache.</p></td></tr></table></div></li></ol></div></li><li class="listitem"><p><a id="install-resource-limits"></a> (Optional) Setup Resource Requests and Limits</p><p>It is a good practice to specify resource requests and limit values.
For each Harbor component, it is possible to specify a minimal resource value — that is, the amount of CPU units and memory it should get — and a limit value, so that Kubernetes knows the resources given to a component cannot exceed the limit.
These per-component values are used for all containers that are created for a given Harbor component.</p><p>For example, add the following section to <code class="literal">harbor-values.yaml</code> to specify that the containers from the core component should get at least 0.1 CPU, 256 MiB of RAM, and not more than 1 CPU and 1 GiB of memory:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">core:
  resources:
    requests:
      memory: 256Mi
      cpu: 100m
    limits:
      cpu: 1
      memory: 1Gi</pre><p>
</p><p>Read more about Resource management in the <a class="link" href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/" target="_top">upstream documentation</a>.</p></li><li class="listitem"><p><a id="install-resource-accounts"></a> (Optional) Use distinct Service Accounts</p><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Note</h3><p>You can use distinct Service Accounts for each Harbor component.</p><p>Refer to the <a class="link" href="https://kubernetes.io/docs/concepts/policy/pod-security-policy/" target="_top">upstream documentation</a> to find out more about Pod Security Policies.</p></div><p>Without any changes, all created Pods belong to the default Service Account. For better overall cluster security, we recommend creating a Pod Security Policy that restricts the Pods to only  specific actions.
Then you can assign new ServiceAccounts to your Pod Security Policy using Roles and Role Bindings.</p><p>For example, if you created a <code class="literal">suse-registry</code> Service Account, add the following section to the <code class="literal">harbor-values.yaml</code> file so that all Harbor services are associated with it:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">nginx:
  serviceAccountName: "suse-registry"
portal:
  serviceAccountName: "suse-registry"
core:
  serviceAccountName: "suse-registry"
jobservice:
  serviceAccountName: "suse-registry"
registry:
  serviceAccountName: "suse-registry"
trivy:
  serviceAccountName: "suse-registry"
notary:
  server:
    serviceAccountName: "suse-registry"
  signer:
    serviceAccountName: "suse-registry"
database:
  internal:
    serviceAccountName: "suse-registry"
redis:
  internal:
    serviceAccountName: "suse-registry"</pre><p>
</p></li><li class="listitem"><p><a id="install-passwords"></a> Set up the passwords for deployment</p><p>By default, all passwords are automatically generated when installing SUSE Private Registry with the Helm chart. They can be retrieved post-installation from the created Kubernetes secrets objects. For example, to retrieve the Harbor administrator password necessary to log in into the Harbor Portal UI as admin user, run this command after the deployment is finished:</p><pre class="screen">kubectl get secret suse-registry-harbor-core -n registry -o jsonpath="{.data.HARBOR_ADMIN_PASSWORD}" | base64 --decode</pre><p>To set a custom administrator password before the installation, modify your <code class="literal">harbor-values.yaml</code> file like this:</p><p><strong>harbor-config-values.yaml. </strong>
</p><pre class="screen">harborAdminPassword: &lt;password-for-admin-user&gt;</pre><p>
</p><p>Similarly, custom passwords may be set before the installation for the database and Redis services, if configured as internal services:</p><p><strong>harbor-config-values.yaml. </strong>
</p><pre class="screen">database:
  ...
  internal:
    password: &lt;password-for-redis&gt;

redis:
  ...
  internal:
    password: &lt;password-for-redis&gt;</pre><p>
</p></li><li class="listitem"><p>Finally, deploy helm to install SUSE Private Registry</p><p>To install SUSE Private Registry as a <code class="literal">suse-registry</code> release into the registry namespace with the custom configuration prepared in <code class="literal">harbor-values.yaml</code> in the previous steps, run the following command:</p><pre class="screen">helm -n registry install suse-registry ./harbor -f harbor-values.yaml</pre><p>Once the installation is complete, Helm will provide the information about the location of the newly installed registry, e.g.:</p><pre class="screen">NAME: suse-registry
LAST DEPLOYED: Fri Jul 24 10:34:53 2020
NAMESPACE: registry
STATUS: deployed
REVISION: 1
NOTES:
Please wait for several minutes for Harbor deployment to complete.
Then you should be able to visit the Harbor portal at https://core.harbor.domain <a id="CO4-1"></a><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></pre><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO4-1"><span><img src="static/images/callouts/1.png" alt="1" border="0" /></span></a> </p></td><td valign="top" align="left"><p>You will see your <code class="literal">&lt;core_fqdn&gt;</code> instead of <code class="literal"><a class="link" href="https://core.harbor.domain" target="_top">https://core.harbor.domain</a></code>.</p></td></tr></table></div></li><li class="listitem"><p>Check the installation</p><p>You can check the status of created artifacts and see if everything is running correctly:</p><pre class="screen">&gt; kubectl -n registry get deployments
NAME                              READY   UP-TO-DATE   AVAILABLE   AGE
suse-registry-harbor-core         1/1     1            1           17h
suse-registry-harbor-jobservice   1/1     1            1           17h
suse-registry-harbor-portal       1/1     1            1           17h
suse-registry-harbor-registry     1/1     1            1           17h</pre><pre class="screen">&gt; kubectl -n registry get pods
NAME                                                  READY   STATUS    RESTARTS   AGE
suse-registry-harbor-core-c787885b6-2l7lz             1/1     Running   1          105m
suse-registry-harbor-database-0                       1/1     Running   0          105m
suse-registry-harbor-jobservice-698fb5bb44-88mc5      1/1     Running   1          105m
suse-registry-harbor-nginx-b4f7748c5-8v2rp            1/1     Running   0          105m
suse-registry-harbor-portal-bff5898cc-tt9ss           1/1     Running   0          105m
suse-registry-harbor-redis-0                          1/1     Running   0          105m
suse-registry-harbor-registry-7f65b6f87b-sqhzt        2/2     Running   0          105m
suse-registry-harbor-trivy-0                          1/1     Running   0          105m</pre></li></ol></div><p>After the installation is complete, please proceed with <a class="xref" href="administration.html" title="Administration">the section called “Administration”</a> and configure an authentication method.</p></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="high-availability.html">Prev</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="id-deployment-in-an-air-gapped-environment.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">High Availability </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> Deployment in an Air-Gapped Environment </td></tr></table></div></body></html>
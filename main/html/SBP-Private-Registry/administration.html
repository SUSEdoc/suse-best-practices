<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Administration</title><meta name="generator" content="DocBook XSL Stylesheets V1.79.2" /><style type="text/css">
body { background-image: url('static/images/draft.png');
       background-repeat: no-repeat;
       background-position: top left;
       /* The following properties make the watermark "fixed" on the page. */
       /* I think that's just a bit too distracting for the reader... */
       /* background-attachment: fixed; */
       /* background-position: center center; */
     }</style><link rel="home" href="index.html" title="SUSE Private Registry Powered by Harbor 2.1" /><link rel="up" href="index.html" title="SUSE Private Registry Powered by Harbor 2.1" /><link rel="prev" href="install-tls-security.html" title="Transport Layer Security (TLS) Setup" /><link rel="next" href="user-guide.html" title="User Guide" /></head><body onload="$('#betawarn-button-wrap').toggle();if (document.cookie.length > 0) {if (document.cookie.indexOf('betawarn=closed') != -1){$('#betawarn').toggle()}};"><div id="betawarn" style="position:fixed;bottom:0;z-index:9025;background-color:#FDE8E8;padding:1em;margin-left:10%;margin-right:10%;display:block;border-top:.75em solid #E11;width:80%"><p style="color:#333;margin:1em 0;padding:0;">This is a draft document that was built and uploaded automatically. It may document beta software and be incomplete or even incorrect. <strong>Use this document at your own risk.</strong></p> <div id="betawarn-button-wrap" style="display:none;margin:0;padding:0;"><a href="#" onclick="$('#betawarn').toggle();var d=new Date();d.setTime(d.getTime()+(0.5*24*60*60*1000));document.cookie='betawarn=closed; expires='+d.toUTCString()+'; path=/'; return false;" style="color:#333;text-decoration:underline;float:left;margin-top:.5em;padding:1em;display:block;background-color:#FABEBE;">I understand this is a draft</a></div></div><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">Administration</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="install-tls-security.html">Prev</a> </td><th width="60%" align="center"> </th><td width="20%" align="right"> <a accesskey="n" href="user-guide.html">Next</a></td></tr></table><hr /></div><div class="section"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="administration"></a>Administration</h2></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-setup-administration-access"></a>Setup Administration Access</h3></div></div></div><p>SUSE Private Registry User Interface can be accessed from a supported web browser at the location provided as <code class="literal">&lt;core_fqdn&gt;</code> during the installation.
Find out about the initial admin user password in <a class="xref" href="id-deployment-of-suse-private-registry.html#install-passwords">[install-passwords]</a>.</p><div class="informalfigure"><div class="mediaobject"><table border="0" summary="manufactured viewport for HTML img" style="cellpadding: 0; cellspacing: 0;" width="80%"><tr><td><img src="images/registry-harbor-landingpage.png" width="100%" alt="registry harbor landingpage" /></td></tr></table></div></div><p>After the first login, you can change the administrator’s password through the web UI. Select the <span class="strong"><strong>admin</strong></span> tab and select <span class="strong"><strong>Change Password</strong></span>.</p><div class="informalfigure"><div class="mediaobject"><table border="0" summary="manufactured viewport for HTML img" style="cellpadding: 0; cellspacing: 0;" width="80%"><tr><td><img src="images/registry-harbor-admin-pw-change.png" width="100%" alt="registry harbor admin pw change" /></td></tr></table></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="admin-configure-authentication"></a>Configuring Authentication</h3></div></div></div><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Switching Authentication Mode</h3><p>Once a user (besides the admin) is registered, or logs in when using LDAP/AD or UAA, SUSE Private Registry is locked in the current authentication mode meaning that it is not possible switch to a different authentication mode.
In that way, an authentication mode should be configured as soon as SUSE Private Registry is deployed.</p></div><p>Harbor supports different modes for authenticating users and managing user accounts. The following authentication modes are supported by SUSE Private Registry:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p><span class="strong"><strong>Database (default)</strong></span>: User accounts are created/managed directly in SUSE Private Registry. The user accounts are stored on the SUSE Private Registry database.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP/Active Directory</strong></span>: SUSE Private Registry is configured to use an external external LDAP/Active Directory server for user authentication. The user accounts are created and managed by the LDAP/AD provider.</p></li><li class="listitem"><p><span class="strong"><strong>UAA</strong></span>: SUSE Private Registry is configured to authenticate using an external UAA provider. The user accounts are created and managed by the UAA provider.</p></li></ul></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-database-authentication"></a>Database Authentication</h4></div></div></div><p>In database authentication mode, user accounts are stored in the local database.
By default, only the SUSE Private Registry system administrator can create new user accounts. However, It is also possible to configure SUSE Private Registry to allow self-registration.</p><p>Configuring SUSE Private Registry with Database authentication mode:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Log in to the SUSE Private Registry interface with an account that has system administrator privileges.</p></li><li class="listitem"><p>Under <span class="strong"><strong>Administration</strong></span>, go to <span class="strong"><strong>Configuration</strong></span> and select the <span class="strong"><strong>Authentication</strong></span> tab.</p></li><li class="listitem"><p>Leave <span class="strong"><strong>Auth Mode</strong></span> set to the default <span class="strong"><strong>Database</strong></span> option.</p></li><li class="listitem"><p>(Optionally) Select the <span class="strong"><strong>Allow Self-Registration</strong></span> check box for allowing users to register themselves in SUSE Private Registry.
Self-registration is <span class="emphasis"><em>disabled by default</em></span>. If enabled unregistered users can sign up for a SUSE Private Registry account by clicking <span class="strong"><strong>Sign up for an account</strong></span> on the SUSE Private Registry log in page.</p></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-ldapactive-directory-authentication"></a>LDAP/Active Directory Authentication</h4></div></div></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>Note that self-registration, creating users, deleting users, changing passwords, and resetting passwords is not supported in LDAP/AD authentication mode as users are managed by LDAP/AD.</p></div><p>When using LDAP/AD authentication, users whose credentials are stored in an external LDAP or AD server can log in to SUSE Private Registry directly.
In this case, it is not necessary to create user accounts in SUSE Private Registry.</p><p>To be able to manage user authentication by using LDAP groups, it is required to enable the <code class="literal">memberof</code> feature on the LDAP/AD server.
With the <code class="literal">memberof</code> feature, the LDAP/AD user entity’s <code class="literal">memberof</code> attribute is updated when the group entity’s member attribute is updated, for example by adding or removing an LDAP/AD user from the LDAP/AD group.</p><p>The following steps describe how to enable LDAP/AD authentication mode:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Log in to the SUSE Private Registry interface with an account that has system administrator privileges.</p></li><li class="listitem"><p>Under <span class="strong"><strong>Administration</strong></span>, go to <span class="strong"><strong>Configuration</strong></span> and select the <span class="strong"><strong>Authentication</strong></span> tab.</p></li><li class="listitem"><p>Use the <span class="strong"><strong>Auth Mode</strong></span> drop-down menu to select <span class="strong"><strong>LDAP</strong></span>.</p></li><li class="listitem"><p>Enter the address of the LDAP server, for example <code class="literal">ldaps://10.84.5.171</code>.</p></li><li class="listitem"><p>Enter information about the LDAP server as follows:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p><span class="strong"><strong>LDAP Search DN</strong></span> and <span class="strong"><strong>LDAP Search Password</strong></span>: When a user logs in to SUSE Private Registry with their LDAP username and password, it uses these values to bind to the LDAP/AD server.
For example, <code class="literal">cn=admin,dc=example.com</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Base DN</strong></span>: SUSE Private Registry looks up the user under the LDAP Base DN entry, including the subtree. For example, <code class="literal">dc=example.com</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Filter</strong></span>: The filter to search for LDAP/AD users. For example, <code class="literal">objectclass=user</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP UID</strong></span>: An attribute, for example uid, or cn, that is used to match a user with the username.
If a match is found, the user’s password is verified by a bind request to the LDAP/AD server.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Scope</strong></span>: The scope to search for LDAP/AD users. Select from <span class="strong"><strong>Subtree</strong></span>, <span class="strong"><strong>Base</strong></span>, and <span class="strong"><strong>OneLevel</strong></span>.</p></li></ol></div></li><li class="listitem"><p>To be able to manage user authentication with LDAP groups, configure the group settings:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p><span class="strong"><strong>LDAP Group Base DN</strong></span>: The base DN from which to lookup a group in LDAP/AD. For example, <code class="literal">ou=groups,dc=example,dc=com</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Group Filter</strong></span>: The filter to search for LDAP/AD groups. For example, <code class="literal">objectclass=groupOfNames</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Group GID</strong></span>: The attribute used to name an LDAP/AD group. For example, <code class="literal">cn</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Group Admin DN</strong></span>: All LDAP/AD users in this group DN have Harbor system administrator privileges.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Group Membership</strong></span>: The user attribute usd to identify a user as a member of a group. By default this is <code class="literal">memberof</code>.</p></li><li class="listitem"><p><span class="strong"><strong>LDAP Scope</strong></span>: The scope to search for LDAP/AD groups. Select from <span class="strong"><strong>Subtree</strong></span>, <span class="strong"><strong>Base</strong></span>, and <span class="strong"><strong>OneLevel</strong></span>.</p></li></ol></div></li><li class="listitem"><p>Uncheck <span class="strong"><strong>LDAP Verify Cert</strong></span> if the LDAP/AD server uses a self-signed or untrusted certificate.</p></li><li class="listitem"><p>Click <span class="strong"><strong>Test LDAP Server</strong></span> to make sure that your configuration is correct.</p></li><li class="listitem"><p>Click <span class="strong"><strong>Save</strong></span> to complete the configuration.</p></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-uaa-authentication"></a>UAA Authentication</h4></div></div></div><p>By configuring UAA authentication, users whose credentials are stored in an external UAA server can log in to SUSE Private Registry directly. In this case, it is not necessary to create user accounts in SUSE Private Registry. Note that just like LDAP authentication mode, self-registration, creating users, deleting users, changing passwords, and resetting passwords are not supported in UAA authentication mode as users are managed by UAA.</p><p>The following steps describe how to configure UAA authentication mode:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Register a client account on UAA. For example, using the UAA CLI and assuming the UAA server is available at <code class="literal">http://10.83.7.181:8080</code>:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Configure UAA CLI to target the UAA server and login as admin:</p><pre class="screen">$ uaac target http://10.83.7.181:8080/uaa</pre><pre class="screen">$ uaac token client get admin -s &lt;admin_secret&gt; # replace &lt;admin_secret&gt; with the secret of the admin user</pre></li><li class="listitem"><p>Register a client account for SUSE Private Registry:</p><pre class="screen">$ uaac client add suse_private_registry -s suseprivateregistrysupersecret --scope uaa.user --authorized_grant_types client_credentials,password --authorities oauth.login</pre></li></ol></div></li><li class="listitem"><p>Log in to the SUSE Private Registry interface with an account that has system administrator privileges.</p></li><li class="listitem"><p>Under <span class="strong"><strong>Administration</strong></span>, go to <span class="strong"><strong>Configuration</strong></span> and select the <span class="strong"><strong>Authentication</strong></span> tab.</p></li><li class="listitem"><p>Use the <span class="strong"><strong>Auth Mode</strong></span> drop-down menu to select UAA.</p></li><li class="listitem"><p>Enter the address of the UAA server token endpoint, for example <code class="literal">http://10.83.7.181:8080/uaa/oauth/token</code></p></li><li class="listitem"><p>Enter information about the UAA client account as follows:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p><span class="strong"><strong>UAA Client ID</strong></span>: The client account ID. For example <code class="literal">suse_private_registry</code> as created on step 1.</p></li><li class="listitem"><p><span class="strong"><strong>UAA Client Secret</strong></span>: The client account secret. For example <code class="literal">suseprivateregistrysupersecret</code> as created on step 1.</p></li></ol></div></li><li class="listitem"><p>Uncheck <span class="strong"><strong>UAA Verify Cert</strong></span> if the UAA server uses a self-signed or untrusted certificate.</p></li><li class="listitem"><p>Click <span class="strong"><strong>Save</strong></span> to complete the configuration.</p></li></ol></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-registry-deployment-configuration-changes"></a>Registry Deployment Configuration Changes</h3></div></div></div><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Updating the Registry Deployment Configuration</h3><p>Changing the deployment configuration of a running SUSE Private Registry instance involves running <code class="literal">helm upgrade</code> in some form or other. The <code class="literal">harbor-values.yaml</code> file used during installation to provide the initial SUSE Private Registry configuration should be treated as the source of truth during all subsequent deployment configuration changes and upgrade operations.
For all SUSE Private Registry configuration change operations documented in this section, it is therefore highly recommended that the <code class="literal">harbor-values.yaml</code> be updated accordingly, and that the file be supplied to the <code class="literal">helm upgrade</code> command, instead of using additional <code class="literal">--set</code> command line arguments that are not be persisted.</p><p>Disregarding this recommendation may lead to situation in which the configuration of the running SUSE Private Registry installation is no longer in sync with the configuration described in the <code class="literal">harbor-values.yaml</code> file, which will cause unexpected configuration changes during upgrade operations.</p></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>Some SUSE Private Registry deployment configuration changes require restarting one or several of the registry components. To reduce service downtime while configuration changes are being applied, it is recommended to run SUSE Private Registry in high-availability mode (see <a class="xref" href="high-availability.html" title="High Availability">the section called “High Availability”</a> for more information).</p></div><p>Examples of supported post-installation deployment configuration changes, some of which are further documented in the sub-sections that follow:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Enabling or disabling internal TLS</p></li><li class="listitem"><p>Adding custom CA certificate bundles into the trust store used by SUSE Private Registry components</p></li><li class="listitem"><p>Rotating TLS certificates</p></li><li class="listitem"><p>Increasing the size of Kubernetes persistent volumes used by SUSE Private Registry components</p></li><li class="listitem"><p>Changing passwords, tokens and access keys</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>The password for the database admin</p></li><li class="listitem"><p>The password for the redis default account</p></li><li class="listitem"><p>The github token used by trivy to regularly update the vulnerability database</p></li></ul></div></li><li class="listitem"><p>Changing the update strategy used for rolling updates</p></li><li class="listitem"><p>Changing the scale (replica count) for SUSE Private Registry services</p></li><li class="listitem"><p>Changing the Kubernetes service accounts associated with SUSE Private Registry pods</p></li><li class="listitem"><p>Enable or disable the <code class="literal">notary</code> component</p></li><li class="listitem"><p>Enable or disable <code class="literal">trivy</code> component</p></li></ul></div><p>The following post-installation deployment configuration changes are not supported and require a full SUSE Private Registry re-installation:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Changing the storage type for the OCI artifact storage</p></li><li class="listitem"><p>Changing the storage class for Kubernetes persistent volumes</p></li><li class="listitem"><p>Decreasing the size of Kubernetes persistent volumes used by SUSE Private Registry components</p></li><li class="listitem"><p>Replacing the redis service</p></li><li class="listitem"><p>Replacing the database service</p></li></ul></div><p>Helm configuration changes can usually be applied by updating the SUSE Private Registry <code class="literal">harbor-values.yaml</code> configuration file used during installation with the new configuration values and then running <code class="literal">helm upgrade</code> to apply the changes. Cases that required additional steps are explicitly documented in the sub-sections that follow.</p><div class="tip" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Tip</h3><p>The full list of deployment configuration options and default values that can overridden in the <code class="literal">harbor-values.yaml</code> file is included in the helm chart itself and can be viewed in YAML format by running the following command:</p><pre class="screen">helm show values harbor</pre><p>The SUSE Private Registry Deployment section also contains extended information on the most relevant helm configuration options.
Those configuration options can be customized not only during installation but also updated post-installation, with the exceptions documented earlier in this section as not supported.</p></div><p>For example, to enable internal TLS, <code class="literal">notary</code> and <code class="literal">trivy</code> in one go (assuming they are all currently disabled), update the <code class="literal">harbor-values.yaml</code> configuration file and run <code class="literal">helm upgrade</code> as follows:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">internalTLS:
  enabled: true
trivy:
  enabled: true
  replicas: 3
  gitHubToken: "&lt;github-auth-token&gt;"
notary:
  enabled: true
  server:
    replicas: 3
  signer:
    replicas: 3</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-changing-the-database-password"></a>Changing the Database Password</h4></div></div></div><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Caution</h3><p>Changing the database password is an administrative operation that has impact on service availability.</p></div><p>The password for the SUSE Private Registry internal or external database service can be changed in three steps:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>First, shutdown all SUSE Private Registry services that use the database, to eliminate the risk of incomplete or failed transactions:</p><pre class="screen">kubectl -n registry scale deployment -l component=core --replicas=0
kubectl -n registry scale deployment -l component=notary-server --replicas=0
kubectl -n registry scale deployment -l component=notary-signer --replicas=0</pre></li><li class="listitem"><p>Change the password for the database server</p><p>For an external database, use the means available from the public cloud provider to set a new admin password.</p><p>For the internal database, the easiest way to do this is by accessing the database pod via <code class="literal">kubectl exec</code> and running a <code class="literal">psql</code> command to change the password, e.g.:</p><pre class="screen">kubectl -n registry exec -ti harbor-harbor-database-0 -- psql
psql (12.4)
Type "help" for help.

postgres=# \password
Enter new password: &lt;new-password-value&gt;
Enter it again: &lt;new-password-value&gt;
postgres=# \q</pre></li><li class="listitem"><p>Update the SUSE Private Registry <code class="literal">harbor-values.yaml</code> configuration file with the new password value and run <code class="literal">helm upgrade</code> to apply the change and start the services that were stopped at the first step:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">database:
  internal:
    ...
    # use this field for the internal database
    password: "&lt;new password value&gt;"
  external:
    ...
    # use this field for the external database
    password: "&lt;new password value&gt;"</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-changing-the-redis-password"></a>Changing the Redis Password</h4></div></div></div><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Caution</h3><p>Changing the redis password is an administrative operation that has impact on service availability.</p></div><p>The password for the SUSE Private Registry redis service can be changed in two steps:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>First, change the password for the redis service itself</p><p>For an internal redis service, nothing needs to be done at this step.</p><p>If you’re running an external public cloud redis service, change the external redis password using the means available from the public cloud provider.</p><p>For a redis service deployed using the SUSE redis operator, the password can be changed as follows:</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p>Update the secret created during installation with the new password:</p><pre class="screen">helm -n registry delete secret redis-auth
kubectl -n registry create secret generic redis-auth --from-literal=password="&lt;new-password-value&gt;"</pre></li><li class="listitem"><p>Delete the running redis statefulset to force a configuration update:</p><pre class="screen">helm -n registry delete statefulset -l app.kubernetes.io/component=redis</pre></li></ol></div></li><li class="listitem"><p>Update the SUSE Private Registry <code class="literal">harbor-values.yaml</code> configuration file with the new password value and run <code class="literal">helm upgrade</code> to apply the change:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">redis:
  internal:
    ...
    # use this field for the internal redis
    password: "&lt;new password value&gt;"
  external:
    ...
    # use this field for the external redis
    password: "&lt;new password value&gt;"</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-rotating-autogenerated-tls-certificates"></a>Rotating Autogenerated TLS Certificates</h4></div></div></div><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Rotate certificates on minor version upgrades</h3><p>Certificate rotation is an administrative operation that impacts service availability.
The certificates auto-generated by helm have a validity of 365 days, sufficient to not require rotating them too frequently.
It is advised that all auto-generated certificates be rotated with every upgrade operation consisting in a minor or major version number change, to avoid loss of operation, but it is not required to do so more frequently.</p></div><p>The SUSE Private Registry helm chart provides the option to auto-generate certificates, if custom certificates aren’t explicitly provided. This applies to the following certificates and their use:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>TLS certificates for the publicly exposed APIs: the Harbor UI/API and the notary API</p><p>A single certificate is generated for both endpoints, if <code class="literal">tls.certSource</code> is set to <code class="literal">auto</code> in the helm chart configuration.</p></li><li class="listitem"><p>TLS certificates for the internal communication</p><p>A certificate is generated for every SUSE Private Registry component that exposes an API consumed internally by other components (<code class="literal">core</code>, <code class="literal">jobservice</code>, <code class="literal">registry</code>, <code class="literal">portal</code> and <code class="literal">trivy</code>), if <code class="literal">internalTLS.enabled</code> is set to <code class="literal">true</code> and <code class="literal">internalTLS.certSource</code> is set to <code class="literal">auto</code> in the helm chart configuration.</p></li><li class="listitem"><p>A TLS certificate is used to secure the <code class="literal">notary-signer</code> internal API</p><p>This is handled independently of the global <code class="literal">internalTLS.enable</code> flag controlling internal TLS for other SUSE Private Registry components, because, for technical reasons, internal TLS cannot be disabled for the <code class="literal">notary-signer</code> component.
A certificate is automatically generated unless <code class="literal">notary.secretName</code> is set to point to a predefined secret providing a custom TLS certificate for this component.</p></li><li class="listitem"><p>A TLS certificate and private key pair are used by the SUSE Private Registry <code class="literal">core</code> component to generate encryption/decryption tokens for use by robot accounts</p><p>A certificate is automatically generated unless <code class="literal">core.secretName</code> is set to point to a predefined secret providing a custom TLS certificate and private key pair for this purpose.</p></li></ul></div><p>By default, auto-generated TLS certificates are created during the initial SUSE Private Registry installation and kept unchanged during subsequent helm runs.
To re-generate these TLS certificates, the relevant <code class="literal">rotateCert</code> configuration flags need to be explicitly set during the helm runs, as detailed in the remainder of this section.</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>Rotating the certificates autogenerated for the Harbor UI/API and notary API will invalidate the CA certificates already configured on the remote hosts where these SUSE Private Registry services are accessed. See the <a class="xref" href="install-tls-security.html" title="Transport Layer Security (TLS) Setup">the section called “Transport Layer Security (TLS) Setup”</a> section for details on how to reconfigure these hosts.</p></div><p>To rotate the TLS certificates auto-generated for the publicly exposed APIs, run:</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml --set expose.tls.auto.rotateCert=true</pre><p>This operation can be performed with zero downtime, the SUSE Private Registry services themselves are not impacted by it.</p><p>To rotate the TLS certificates auto-generated for the internal communication (including <code class="literal">notary-server</code>), run:</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml --set internalTLS.rotateCert=true --set notary.rotateCert=true</pre><p>This operation requires all SUSE Private Registry components to be updated</p><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>Rotating the TLS certificate and private key pair autogenerated for encryption/decryption of tokens for robot accounts will invalidate the existing tokens.</p></div><p>To re-generate the TLS certificate and private key pair used for encryption/decryption of tokens for robot accounts, run:</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml --set core.rotateCert=true</pre></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-scaling-the-registry-services"></a>Scaling the Registry Services</h4></div></div></div><div class="warning" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Warning</h3><p>A Kubernetes <code class="literal">StorageClass</code> with <code class="literal">ReadWriteMany</code> access mode is required to enable high-availability for the SUSE Private Registry <code class="literal">registry</code> component, if a Kubernetes persistent volume is used as the storage back-end for OCI artifacts.
If a <code class="literal">StorageClass</code> with <code class="literal">ReadWriteMany</code> access is not configured for these components, setting the replica count to a value higher than 1 for them will result in failure.</p></div><p>To change the scale parameters for the internal components of a running SUSE Private Registry instance, update the <code class="literal">harbor-values.yaml</code> configuration file with new replica values, as desired, and then apply the change by running <code class="literal">helm upgrade</code> with the same parameters used during installation:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">portal:
  replicas: 3
core:
  replicas: 3
# Only enabled when using a LoadBalancer instead of Ingress to expose services
nginx:
  replicas: 3
jobservice:
  replicas: 3
registry:
  replicas: 3
trivy:
  replicas: 3
notary:
  server:
    replicas: 3
  signer:
    replicas: 3</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre><p>Alternatively, <code class="literal">kubectl</code> may be used directly to scale SUSE Private Registry components individually, but special care should be taken to keep the <code class="literal">harbor-values.yaml</code> file updated to reflect the running configuration, otherwise subsequent configuration changes or upgrade operations that require running <code class="literal">helm upgrade</code> will revert the number of replicas back to the known configuration. For example, to scale the <code class="literal">portal</code> component to a new value of 3 pods, the following command may be used:</p><pre class="screen">kubectl -n registry scale deployment -l component=portal --replicas=3</pre></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-expanding-persistent-volumes-claims"></a>Expanding Persistent Volumes Claims</h4></div></div></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Expanding Volumes Containing a File System</h3><p>It is only possible to resize volumes containing a file system if the file system is XFS, Ext3, or Ext4.</p><p>When a volume contains a file system, the file system is only resized when a new Pod is using the <code class="literal">PersistentVolumeClaim</code> in <code class="literal">ReadWrite</code> mode.
File system expansion is either done when a Pod is starting up or when a Pod is running and the underlying file system supports online expansion.</p></div><div class="caution" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Risk of Data Loss</h3><p>It is extremely advised to perform a backup of the existing volumes that will be resized before taking any action as there is a risk of permanent data loss.</p></div><p>Only specific storage providers offer support for expanding <code class="literal">PersistentVolumeClaims</code> (PVCs).
Before taking any action, it is recommended to check the documentation of the storage provider available for your Kubernetes cluster and make sure that it supports expanding PVCs.</p><p>To be able to expand a PVC the storage class’s <code class="literal">allowVolumeExpansion</code> field needs to be set to true. For example:</p><pre class="screen">kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: persistent
  annotations:
    storageclass.kubernetes.io/is-default-class: 'true'
provisioner: kubernetes.io/cinder
reclaimPolicy: Delete
volumeBindingMode: Immediate
allowVolumeExpansion: true</pre><div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id-expanding-volumes-managed-by-deployments-registry-jobservice"></a>Expanding Volumes Managed by Deployments (<code class="literal">registry</code>, <code class="literal">jobservice</code>)</h5></div></div></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Storage backend without support for online expansion</h3><p>If the storage backend does not support online expansion, additional steps that impact the service availability are required to conclude the resizing.</p></div><p>To resize the PVC for the registry and the <code class="literal">jobservice</code> components of SUSE Private Registry, update the <code class="literal">harbor-values.yaml</code> configuration file with the new storage sizes for the <code class="literal">registry</code> and <code class="literal">jobservice</code> components, then apply the change by running <code class="literal">helm upgrade</code> with the same parameters used during installation, e.g.:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">persistence:
  persistentVolumeClaim:
    registry:
      ...
      size: 100Gi
    jobservice:
      ...
      size: 5Gi</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre><p>The above command will set the PVC size of the <code class="literal">jobservice</code> component to 5 gigabytes and 100 gigabytes for the <code class="literal">registry</code> PVC.</p><p>If the storage backend supports online expansion the PVCs will be automatically resized and no additional action is needed.
However, If the storage backend does not support online expansion additional steps are required to conclude the volume resize which includes deleting the pods that are using the volume being resized, waiting for the volume to be resized and finally starting new pods. For example, to finalize the resize of the <code class="literal">jobservice</code> PVC when volume online expansion is not supported:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Check the status of the PVC to make sure it is waiting for the volume to be detached to perform the resize:</p><pre class="screen">kubectl -n registry describe pvc -l component=jobservice | sed -n -e '/Conditions/,$p'
Conditions:
  Type       Status  LastProbeTime                     LastTransitionTime                Reason  Message
  ----       ------  -----------------                 ------------------                ------  -------
  Resizing   True    Mon, 01 Jan 0001 00:00:00 +0000   Fri, 23 Oct 2020 17:56:33 +0200
Events:
  Type     Reason                 Age                 From                         Message
  ----     ------                 ----                ----                         -------
  Normal   ProvisioningSucceeded  2m34s               persistentvolume-controller  Successfully provisioned volume pvc-297dfa22-0711-4b43-bea0-cdb3684bc2a0 using kubernetes.io/&lt;plugin&gt;
  Warning  VolumeResizeFailed     31s (x13 over 73s)  volume_expand                error expanding volume "suse-registry/suse-registry-harbor-jobservice" of plugin "kubernetes.io/&lt;plugin&gt;": volume in in-use status can not be expanded, it must be available and not attached to a node</pre></li><li class="listitem"><p>Set the number of replicas of the <code class="literal">jobservice</code> deployment to 0 (this will delete the <code class="literal">jobservice</code> pods and the service will be unavailable):</p><pre class="screen">kubectl -n registry scale deployment -l component=jobservice --replicas=0
deployment.apps/suse-registry-harbor-jobservice scaled</pre></li><li class="listitem"><p>Check the status of the PVC, wait until the volume resize is complete and its just waiting for the pod to start to finish resizing the file system:</p><pre class="screen">kubectl -n registry describe pvc -l component=jobservice | sed -n '/Conditions/,/Events/p'
Conditions:
  Type                      Status  LastProbeTime                     LastTransitionTime                Reason  Message
  ----                      ------  -----------------                 ------------------                ------  -------
  FileSystemResizePending   True    Mon, 01 Jan 0001 00:00:00 +0000   Fri, 23 Oct 2020 18:02:03 +0200           Waiting for user to (re-)start a pod to finish file system resize of volume on node.</pre></li><li class="listitem"><p>Set the number of replicas back to the previous value (1 in this case) to conclude the resize:</p><pre class="screen">kubectl -n registry scale deployment -l component=jobservice --replicas=1
deployment.apps/suse-registry-harbor-jobservice scaled</pre></li><li class="listitem"><p>Confirm that the file system resize has finished successfully:</p><pre class="screen">kubectl -n registry describe pvc -l component=jobservice | sed -n -e '/Events/,$p'
Events:
...
  Normal   FileSystemResizeSuccessful  52s                   kubelet, caasp-worker-eco-caasp4-upd-eco-2                MountVolume.NodeExpandVolume succeeded for volume "pvc-297dfa22-0711-4b43-bea0-cdb3684bc2a0"</pre></li></ol></div><p>The same steps can be followed to conclude expanding the <code class="literal">registry</code> PVC by replacing <code class="literal">component=jobservice</code> with <code class="literal">component=registry</code> on each command.</p></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id-expanding-volumes-managed-by-statefulsets-database-redis-and-trivy"></a>Expanding Volumes Managed by <code class="literal">StatefulSets</code> (<code class="literal">database</code>, <code class="literal">redis</code> and <code class="literal">trivy</code>)</h5></div></div></div><p>Kubernetes does not officially support volume expansion through <code class="literal">StatefulSets</code>, trying to do so by using helm with new values for PVC size will throw the following error:</p><pre class="screen">Error: UPGRADE FAILED: cannot patch "suse-registry-release-12-harbor-trivy" with kind StatefulSet: StatefulSet.apps "suse-registry-release-12-harbor-trivy" is invalid: spec: Forbidden: updates to statefulset spec for fields other than 'replicas', 'template', and 'updateStrategy' are forbidden</pre><p>This means that the <code class="literal">volumeClaimTemplates</code> field of a <code class="literal">StatefulSet</code> is immutable and cannot be updated with a new value for size.
In that way, extra actions are required to perform the resize of PVCs managed by <code class="literal">StatefulSets</code>.</p><p>The following steps describe how to expand volumes managed by <code class="literal">SatefulSets</code> using the <code class="literal">trivy</code> component as an example.
The same steps can be performed also for the database and <code class="literal">redis</code> components of SUSE Private Registry just by replacing <code class="literal">trivy</code> for database or <code class="literal">redis</code> on each command:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Delete the StatefulSet while keeping the pods running together with any other resource that was managed by the StatefulSet such as the PVC.
This can be done by setting <code class="literal">--cascade=false</code> to the <code class="literal">kubectl delete</code> command, for example:</p><pre class="screen">kubectl -n registry delete sts --cascade=false -l component=trivy
statefulset.apps "suse-registry-harbor-trivy" deleted</pre></li><li class="listitem"><p>Edit the PVC spec with the new size (10 gigabytes in this example), this can be done in many different ways. For example using <code class="literal">kubectl</code> patch:</p><pre class="screen">NEW_SIZE="10Gi"
NAMESPACE="registry"
# depending on the number of replicas, trivy can have more than one PVC.
for pvc in $(kubectl -n $NAMESPACE get pvc -l component=trivy -o name); do
  kubectl -n $NAMESPACE patch $pvc -p "{\"spec\":{\"resources\":{\"requests\":{\"storage\":\"$NEW_SIZE\"}}}}"
done

persistentvolumeclaim/data-suse-registry-harbor-trivy-0 patched
persistentvolumeclaim/data-suse-registry-harbor-trivy-1 patched</pre></li><li class="listitem"><p>Update the <code class="literal">harbor-values.yaml</code> configuration file with the new storage size for the intended component, then apply the change by running <code class="literal">helm upgrade</code> with the same parameters used during installation, to re-define the <code class="literal">StatefulSets</code> with the new size to keep consistency. For trivy, for example:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">persistence:
  persistentVolumeClaim:
    trivy:
      ...
      size: 10Gi</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre></li></ol></div><p>Just like for deployments, if the storage backend supports online expansion the PVCs will be automatically resized and no additional action is needed. However, If the storage backend does not support online expansion additional steps are required to conclude the volume resize which includes deleting the pods that are using the volume being resized, waiting for the volume to be resized and finally starting new pods. For example, to finalize the resize of the trivy PVC when volume online expansion is not supported:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Check the status of the PVCs to make sure it is waiting for the volume to be detached to perform the resize:</p><pre class="screen">kubectl -n registry describe pvc -l component=trivy | sed -n -e '/Conditions/,$p'
Conditions:
  Type       Status  LastProbeTime                     LastTransitionTime                Reason  Message
  ----       ------  -----------------                 ------------------                ------  -------
  Resizing   True    Mon, 01 Jan 0001 00:00:00 +0000   Mon, 26 Oct 2020 13:29:58 +0100
Events:
  Type     Reason                 Age                   From                         Message
  ----     ------                 ----                  ----                         -------
  Normal   ProvisioningSucceeded  8m8s                  persistentvolume-controller  Successfully provisioned volume pvc-8fe4a4b6-83c8-47d0-a266-f8cdbd4e3918 using kubernetes.io/&lt;plugin&gt;
  Warning  VolumeResizeFailed     28s (x17 over 5m57s)  volume_expand                error expanding volume "suse-registry/data-suse-registry-harbor-trivy-0" of plugin "kubernetes.io/&lt;plugin&gt;": volume in in-use status can not be expanded, it must be available and not attached to a node</pre></li><li class="listitem"><p>Set the number of replicas of the trivy statefulset to 0 (this will delete the trivy pods and the service will be unavailable):</p><pre class="screen">kubectl -n registry scale sts -l component=trivy --replicas=0
statefulset.apps/suse-registry-harbor-trivy scaled</pre></li><li class="listitem"><p>Check the status of the PVC, wait until the volume resize is complete and its just waiting for the pod to start to finish resizing the file system:</p><pre class="screen">kubectl -n registry describe pvc -l component=trivy | sed -n '/Conditions/,/Events/p'
Conditions:
  Type                      Status  LastProbeTime                     LastTransitionTime                Reason  Message
  ----                      ------  -----------------                 ------------------                ------  -------
  FileSystemResizePending   True    Mon, 01 Jan 0001 00:00:00 +0000   Mon, 26 Oct 2020 13:40:55 +0100           Waiting for user to (re-)start a pod to finish file system resize of volume on node.</pre></li><li class="listitem"><p>Set the number of replicas back to the previous value (2 in this case) to conclude the resize:</p><pre class="screen">kubectl -n registry scale sts -l component=trivy --replicas=2
deployment.apps/suse-registry-harbor-jobservice scaled</pre></li><li class="listitem"><p>Confirm that the file system resize has finished successfully:</p><pre class="screen">kubectl -n registry describe pvc -l component=trivy | sed -n -e '/Events/,$p'
Events:
...
  Normal   FileSystemResizeSuccessful  64s                   kubelet, caasp-worker-eco-caasp4-upd-eco-2  MountVolume.NodeExpandVolume succeeded for volume "pvc-8fe4a4b6-83c8-47d0-a266-f8cdbd4e3918"</pre></li></ol></div></div></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-installing-maintenance-updates"></a>Installing Maintenance Updates</h3></div></div></div><p>SUSE Private Registry maintenance updates containing new helm chart and container image versions are regularly published to address security vulnerabilities and to fix critical bugs.
These updates do not introduce new features and therefore can be applied in a manner similar to regular helm configuration changes, with minimal disruption to service availability.</p><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>It is highly recommended to install SUSE Private Registry maintenance updates regularly and as frequently as possible, to keep your SUSE Private Registry instance up to date with the latest security patches and fixes for functionality impairing issues.</p></div><div class="important" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Important</h3><p>Installing SUSE Private Registry maintenance updates require restarting one or several of the registry components.
To minimize service downtime while the update is being applied, it is recommended to run SUSE Private Registry in high-availability mode (see <a class="xref" href="high-availability.html" title="High Availability">the section called “High Availability”</a> for more information).</p></div><p>The <code class="literal">harbor-values.yaml</code> file used during installation to provide the initial SUSE Private Registry configuration, as well as during subsequent helm configuration changes is also required to install maintenance updates.</p><p>To check for SUSE Private Registry maintenance updates and subsequently install them:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Download the newest Helm chart version from the official SUSE repository:</p><pre class="screen">export HELM_EXPERIMENTAL_OCI=1
# download a chart from public registry
helm chart pull registry.suse.com/harbor/harbor:1.5
# export the chart to local directory
helm chart export registry.suse.com/harbor/harbor:1.5</pre><p>The output from the <code class="literal">helm chart pull</code> command will indicate the helm chart version that is available in the public registry. Make a note of it:</p><pre class="screen">1.5: Pulling from registry.suse.com/harbor/harbor
ref:     registry.suse.com/harbor/harbor:1.5
digest:  db4731ab843d9837eb83327b735a7c5c19826e225858333a3b9a57668d5d40b8
size:    178.1 KiB
name:    harbor
version: 1.5.2
Status: Chart is up to date for registry.suse.com/harbor/harbor:1.5</pre></li><li class="listitem"><p>Verify the version of the running SUSE Private Registry instance:</p><pre class="screen">&gt; helm -n registry list
NAME         	NAMESPACE    	REVISION	UPDATED                              	STATUS  	CHART       	APP VERSION
suse-registry	registry	6       	2020-11-17 15:20:46.037254 +0200 CEST	deployed	harbor-1.5.1	2.1.1</pre><p>If the helm chart version displayed is the same as the one available from the public registry, your SUSE Private Registry instance is up to date and nothing else needs to be done. Otherwise, maintenance updates are available and can be installed.</p></li><li class="listitem"><p>Trigger the upgrade using the <code class="literal">harbor-values.yaml</code> configuration file:</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre></li><li class="listitem"><p>Check the installation</p><p>The SUSE Private Registry update will take a while to complete, while new pods are being created to replace old pods. You can check the status and see if everything is running correctly, e.g.:</p><pre class="screen">&gt; kubectl -n registry get deployments
NAME                              READY   UP-TO-DATE   AVAILABLE   AGE
suse-registry-harbor-core         2/2     2            2           32d
suse-registry-harbor-jobservice   2/2     2            2           32d
suse-registry-harbor-portal       2/2     2            2           32d
suse-registry-harbor-registry     1/1     1            1           32d</pre><pre class="screen">&gt; kubectl -n registry get statefulset
NAME                            READY   AGE
suse-registry-harbor-database   1/1     32d
suse-registry-harbor-redis      1/1     32d
suse-registry-harbor-trivy      2/2     4d1h</pre><pre class="screen">&gt; kubectl -n registry get pod
NAME                                               READY   STATUS    RESTARTS   AGE
suse-registry-harbor-core-85845f9777-5rkbb         1/1     Running   0          24h
suse-registry-harbor-core-85845f9777-krwk2         1/1     Running   0          24h
suse-registry-harbor-database-0                    1/1     Running   0          24h
suse-registry-harbor-jobservice-7f954f9466-66b2r   1/1     Running   0          24h
suse-registry-harbor-jobservice-7f954f9466-6n96t   1/1     Running   0          24h
suse-registry-harbor-portal-76b465644f-4zmxw       1/1     Running   0          24h
suse-registry-harbor-portal-76b465644f-lndlm       1/1     Running   0          24h
suse-registry-harbor-redis-0                       1/1     Running   0          24h
suse-registry-harbor-registry-65854df7bc-mrfnj     2/2     Running   0          24h
suse-registry-harbor-trivy-0                       1/1     Running   1          24h
suse-registry-harbor-trivy-1                       1/1     Running   0          24h</pre></li></ol></div></div><div class="section"><div class="titlepage"><div><div><h3 class="title"><a id="id-backup-and-restore"></a>Backup and Restore</h3></div></div></div><p>Backup and restore for SUSE Private Registry can be performed by <a class="link" href="https://documentation.suse.com/suse-caasp/4.2/html/caasp-admin/_backup_and_restore_with_velero.html" target="_top">Velero</a>. Velero not only handles this, but also disaster recovery, and the migration of Kubernetes cluster resources and persistent volumes.</p><p>When SUSE Private Registry is deployed together with its internal services (database, Redis and filesystem storage for image and artifacts) Velero is able to fully cover the backup and restore. However, as Velero is only responsible for Kubernetes resources, when SUSE Private Registry is deployed using external service providers, such as managed PostgreSQL database or object storage (Amazon S3 or Azure Blob Storage), additional actions must be performed to ensure the backup of data that is external to the Kubernetes cluster.</p><p>In general, the backup and restore process for SUSE Private Registry can be split in two parts:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Backup and restore of Kubernetes resources (performed by Velero):</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>Namespace</p></li><li class="listitem"><p>Deployment</p></li><li class="listitem"><p>ReplicaSet</p></li><li class="listitem"><p>StatefulSet</p></li><li class="listitem"><p>Endpoint</p></li><li class="listitem"><p>Service</p></li><li class="listitem"><p>Ingress</p></li><li class="listitem"><p>ConfigMap</p></li><li class="listitem"><p>Secret</p></li><li class="listitem"><p>PersistentVolumeClaim</p></li><li class="listitem"><p>PersistentVolume</p></li><li class="listitem"><p>Pod</p></li><li class="listitem"><p>Other CRDs (e.g. <code class="literal">Certificate</code> when using <code class="literal">cert-manager</code> or <code class="literal">RedisFailover</code> when using <code class="literal">redis-operator</code>)</p></li></ul></div></li><li class="listitem"><p>Backup and restore of external services:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p>Database</p></li><li class="listitem"><p>Redis</p></li><li class="listitem"><p>Object Storage</p></li></ul></div></li></ul></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-backup-and-restore-of-kubernetes-resources"></a>Backup and restore of Kubernetes resources</h4></div></div></div><p>The following steps describe how to perform the backup and restore of Kubernetes resources using Velero.</p><div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id-backup"></a>Backup</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Install Velero as described in the <a class="link" href="https://documentation.suse.com/suse-caasp/4.2/html/caasp-admin/_backup_and_restore_with_velero.html" target="_top">documentation</a></p></li><li class="listitem"><p>(optional) If you are using a volume provider that does not support volume snapshots or a volume-snapshot API, or does not have Velero-supported storage plugin, then Velero uses <a class="link" href="https://restic.net/" target="_top">Restic</a> as a generic solution to backing and restoring this sort of persistent volume. To perform a Restic backup of persistent volumes, Velero requires the addition of a specific annotation (<code class="literal">backup.velero.io/backup-volumes=&lt;VOLUME_NAME_1&gt;,&lt;VOLUME_NAME_2&gt;,…​</code>) to the pods that have the volumes mounted. This can be achieved by adding the following entries to the SUSE Private Registry’s Helm chart (<code class="literal">harbor-values.yaml</code>), then performing <code class="literal">helm upgrade</code> to apply the annotations:</p><p><strong>harbor-values.yaml. </strong>
</p><pre class="screen">registry:
  podAnnotations:
    backup.velero.io/backup-volumes: registry-data
trivy:
  podAnnotations:
    backup.velero.io/backup-volumes: data
database:
  podAnnotations:
    backup.velero.io/backup-volumes: database-data
redis:
  podAnnotations:
    backup.velero.io/backup-volumes: data</pre><p>
</p><pre class="screen">helm -n registry upgrade suse-registry ./harbor -f harbor-values.yaml</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">External Services</h3><p>If using an external service, such as a managed PostgreSQL database, you do not need to add the <code class="literal">database</code> entry. The same applies for <code class="literal">redis</code> when using an external Redis, and for <code class="literal">registry</code> when using an external storage back-end for storing images and artifacts.</p></div></li><li class="listitem"><p>Back-up the cluster with the command <code class="literal">velero backup create &lt;backup-name&gt; --include-namespaces &lt;namespace-to-backup&gt;</code>. For example:</p><pre class="screen">&gt; velero backup create registry-backup --include-namespaces registry
Backup request "registry-backup" submitted successfully.
Run `velero backup describe registry-backup` or `velero backup logs registry-backup` for more details.</pre><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Scope of the backup</h3><p>Velero supports backing up all Kubernetes cluster resources; however, in this case, the backup is performed for the registry namespace only. In some cases, such as when using <code class="literal">cert-manager</code> or <code class="literal">redis-operator</code>, you might need to include those namespaces in the backup.</p></div></li><li class="listitem"><p>To check the backup status and ensure its completion, run <code class="literal">velero backup describe &lt;backup-name&gt;</code>. For example:</p><pre class="screen">&gt; velero backup describe registry-backup
Name:         registry-backup
Namespace:    velero
Labels:       velero.io/storage-location=default
Annotations:  &lt;none&gt;

Phase:  Completed

Namespaces:
  Included:  registry
  Excluded:  &lt;none&gt;

Resources:
  Included:        *
  Excluded:        &lt;none&gt;
  Cluster-scoped:  auto

Label selector:  &lt;none&gt;

Storage Location:  default

Snapshot PVs:  auto

TTL:  720h0m0s

Hooks:  &lt;none&gt;

Backup Format Version:  1

Started:    2020-12-17 12:00:12 +0100 CET
Completed:  2020-12-17 12:01:36 +0100 CET

Expiration:  2021-01-16 12:00:12 +0100 CET

Persistent Volumes: &lt;none included&gt;

Restic Backups (specify --details for more information):
  Completed:  4</pre></li></ol></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Backup options</h3><p>For more advanced options, such as scheduling backups and configuring expiration times, check the <a class="link" href="https://documentation.suse.com/suse-caasp/4.2/html/caasp-admin/_backup_and_restore_with_velero.html" target="_top">Velero documentation</a>.</p></div></div><div class="section"><div class="titlepage"><div><div><h5 class="title"><a id="id-restore"></a>Restore</h5></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>If you are restoring onto a new Kubernetes cluster, install Velero by following the <a class="link" href="https://documentation.suse.com/suse-caasp/4.2/html/caasp-admin/_backup_and_restore_with_velero.html" target="_top">CaaSP Velero documentation</a>. Make sure to use the same storage back-end used to perform the backup, so that Velero can access the existing backups. If restoring onto the same cluster, make sure to completely delete the existing SUSE Private Registry deployment, including its namespace.</p></li><li class="listitem"><p>To restore the cluster, run the command <code class="literal">velero restore create &lt;restore-name&gt; --from-backup &lt;backup-name&gt;</code>. For example:</p><pre class="screen">&gt; velero restore create registry-restore --from-backup registry-backup
Restore request "registry-restore" submitted successfully.
Run `velero restore describe registry-restore` or `velero restore logs registry-restore` for more details.</pre></li><li class="listitem"><p>To check the restore status and ensure its completion, run <code class="literal">velero restore describe &lt;restore-name&gt;</code>. For example:</p><pre class="screen">&gt; velero restore describe registry-restore
Name:         registry-restore
Namespace:    velero
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

Phase:  Completed

Errors:
  Velero:     &lt;none&gt;
  Namespaces: &lt;none&gt;

Backup:  registry-backup

Namespaces:
  Included:  *
  Excluded:  &lt;none&gt;

Resources:
  Included:        *
  Excluded:        nodes, events, events.events.k8s.io, backups.velero.io, restores.velero.io, resticrepositories.velero.io
  Cluster-scoped:  auto

Namespace mappings:  &lt;none&gt;

Label selector:  &lt;none&gt;

Restore PVs:  auto

Restic Restores (specify --details for more information):
  Completed:  4</pre></li></ol></div><div class="note" style="margin-left: 0.5in; margin-right: 0.5in;"><h3 class="title">Restore options</h3><p>For more advanced options, such restoring from a scheduled backup, see the <a class="link" href="https://documentation.suse.com/suse-caasp/4.2/html/caasp-admin/_backup_and_restore_with_velero.html" target="_top">Velero documentation</a>.</p></div></div></div><div class="section"><div class="titlepage"><div><div><h4 class="title"><a id="id-backup-and-restore-of-external-services"></a>Backup and restore of external services</h4></div></div></div><p>For backup and restore of external services, see the official documentation of the adopted solution. For example:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: disc; "><li class="listitem"><p>Database:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p><a class="link" href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_CommonTasks.BackupRestore.html" target="_top">Backing up and restoring an Amazon RDS DB instance</a></p></li><li class="listitem"><p><a class="link" href="https://docs.microsoft.com/en-us/azure/postgresql/concepts-backup" target="_top">Backup and restore in Azure Database for PostgreSQL</a></p></li></ul></div></li><li class="listitem"><p>Redis:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p><a class="link" href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/backups.html" target="_top">Backup and Restore for ElastiCache for Redis</a></p></li><li class="listitem"><p><a class="link" href="https://docs.microsoft.com/en-us/azure/azure-cache-for-redis/cache-how-to-premium-persistence" target="_top">How to configure data persistence for a Premium Azure Cache for Redis</a></p></li></ul></div></li><li class="listitem"><p>Object storage:</p><div class="itemizedlist"><ul class="itemizedlist" style="list-style-type: circle; "><li class="listitem"><p><a class="link" href="https://docs.aws.amazon.com/AmazonS3/latest/dev/Versioning.html" target="_top">Amazon Simple Storage Service (S3) Versioning</a></p></li><li class="listitem"><p><a class="link" href="https://docs.microsoft.com/en-us/azure/storage/blobs/versioning-overview" target="_top">Azure Blob Storage versioning</a></p></li></ul></div></li></ul></div></div></div></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="install-tls-security.html">Prev</a> </td><td width="20%" align="center"> </td><td width="40%" align="right"> <a accesskey="n" href="user-guide.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">Transport Layer Security (TLS) Setup </td><td width="20%" align="center"><a accesskey="h" href="index.html">Home</a></td><td width="40%" align="right" valign="top"> User Guide</td></tr></table></div></body></html>